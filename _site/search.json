[
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "For questions or additional information, feel free to contact:\nMari Roberts\nProject Author\nEmail: marialexandriaroberts@gmail.com\nGitHub: @mr4909"
  },
  {
    "objectID": "contact.html#team",
    "href": "contact.html#team",
    "title": "Contact",
    "section": "",
    "text": "For questions or additional information, feel free to contact:\nMari Roberts\nProject Author\nEmail: marialexandriaroberts@gmail.com\nGitHub: @mr4909"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "CalFresh SNAP Application Analysis",
    "section": "",
    "text": "Welcome to the CalFresh SNAP Application Analysis site, created as part of a data science take home assignment for Code for America.\nThe analysis explores factors associated with CalFresh (SNAP) application approvals in San Diego County, based on ~2,000 applications submitted via GetCalFresh.org.\nThis project aims to surface key patterns in approval outcomes and suggest potential improvements to the application process."
  },
  {
    "objectID": "about.html#introduction",
    "href": "about.html#introduction",
    "title": "CalFresh SNAP Application Analysis",
    "section": "",
    "text": "Welcome to the CalFresh SNAP Application Analysis site, created as part of a data science take home assignment for Code for America.\nThe analysis explores factors associated with CalFresh (SNAP) application approvals in San Diego County, based on ~2,000 applications submitted via GetCalFresh.org.\nThis project aims to surface key patterns in approval outcomes and suggest potential improvements to the application process."
  },
  {
    "objectID": "about.html#objectives",
    "href": "about.html#objectives",
    "title": "CalFresh SNAP Application Analysis",
    "section": "Objectives",
    "text": "Objectives\n\nIdentify which applicant characteristics are most strongly associated with approval.\nUnderstand where the process may break down (e.g., interviews, document submission).\nSuggest actionable, user-centered improvements to reduce friction in the process."
  },
  {
    "objectID": "about.html#key-questions",
    "href": "about.html#key-questions",
    "title": "CalFresh SNAP Application Analysis",
    "section": "Key Questions",
    "text": "Key Questions\n\nWhat factors are most strongly associated with CalFresh approval?\nWhere would you look next to improve the application process?"
  },
  {
    "objectID": "about.html#project-links",
    "href": "about.html#project-links",
    "title": "CalFresh SNAP Application Analysis",
    "section": "Project Links",
    "text": "Project Links\n\nGitHub Repository: Link to repo\nExercise Prompt: View exercise PDF\nData Source: Download from Google Drive"
  },
  {
    "objectID": "about.html#stakeholders",
    "href": "about.html#stakeholders",
    "title": "CalFresh SNAP Application Analysis",
    "section": "Stakeholders",
    "text": "Stakeholders\nThis analysis models the collaborative work that would involve:\n\nCode for America’s GetCalFresh team: Program designers and policy advocates.\nCounty Human Services Agencies: Decision-makers and data providers.\nApplicants: The core user base, especially those facing structural barriers to access."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis Walkthrough",
    "section": "",
    "text": "This analysis explores which factors are associated with whether a CalFresh (SNAP) application is approved or denied. The data come from 2,046 applications submitted through GetCalFresh.org in San Diego County.\n\nOur goal is to understand:\n\nWhat factors are associated with whether an applicant is approved or denied\nWhere in the process users may drop off, face barriers, or get delayed\nHow the application experience could be improved for users\n\n\nThis is not a causal analysis. Instead, it aims to show practical insights about patterns in approval outcomes, using variables tied to both applicant eligibility and their interactions with the process."
  },
  {
    "objectID": "analysis.html#key-takeaways-from-the-application-experience",
    "href": "analysis.html#key-takeaways-from-the-application-experience",
    "title": "Analysis",
    "section": "Key Takeaways from the Application Experience",
    "text": "Key Takeaways from the Application Experience\n\nMultilingual Support is available from the start (English, Spanish, Chinese, Vietnamese), with more preferred language options at the end of the process.\nThe application is staged, moving through: household info → income → expenses → contact details → confirmation.\nApplicants receive real-time feedback on whether they may or may not qualify, including notifications about potential expedited processing timelines.\nSubmission does not require everything at once. Document uploads and interviews can happen after submission, making these potential barriers to completion, not eligibility.\n\nToward the end of the process, applicants are asked to:\n\nConfirm contact information (phone, email, language preferences)\nSelect mailing address options — including a note that a mailing address is required for benefit delivery but can be substituted with PO boxes or addresses of trusted third parties\nProvide interview availability and request accommodations (e.g., interpreters, help with disabilities)\nOpt into reminders via SMS and email, which are used to prompt follow-up actions\n\nWalking through the application clarified where users face decision points and delays — especially around optional steps like interviews and document uploads that are not required at submission but can affect outcomes later."
  },
  {
    "objectID": "analysis.html#final-survey-stages-and-what-they-reveal",
    "href": "analysis.html#final-survey-stages-and-what-they-reveal",
    "title": "Analysis",
    "section": "Final Survey Stages and What They Reveal",
    "text": "Final Survey Stages and What They Reveal\nToward the end of the process, applicants are asked to:\n\nConfirm contact information (phone, email, language preferences)\nSelect mailing address options — including a note that a mailing address is required for benefit delivery but can be substituted with PO boxes or addresses of trusted third parties\nProvide interview availability and request accommodations (e.g., interpreters, help with disabilities)\nOpt into reminders via SMS and email, which are used to prompt follow-up actions\n\nPeople can drop off at this stage — just before final submission — for reasons unrelated to eligibility, such as technical issues, unclear instructions, privacy concerns, immigration status concerns, or timing conflicts with the required interview."
  },
  {
    "objectID": "analysis.html#implications-for-data-analysis",
    "href": "analysis.html#implications-for-data-analysis",
    "title": "Analysis",
    "section": "Implications for Data Analysis",
    "text": "Implications for Data Analysis\nThe user experience walk through shaped my interpretation of key fields:\n\nhad_interview: Based on a follow-up text message response, not a verified system event. Missing values do not confirm no interview — just that it wasn’t captured via GetCalFresh.\ndocs_with_app vs. docs_after_app: Reflect when documentation was uploaded through the platform. Counties may have received documents by other means (mail, fax, in person).\ncompletion_time_mins: Captures elapsed time from start to finish, but may reflect interruptions or household complexity — not necessarily user effort or intent."
  },
  {
    "objectID": "analysis.html#codebook",
    "href": "analysis.html#codebook",
    "title": "Analysis Walkthrough",
    "section": "Codebook",
    "text": "Codebook\nTo ground the analysis in a shared understanding of the data, I generated a structured codebook using a custom function from my databookR package. The codebook:\n\nLists all variables in the dataset\nProvides plain-language descriptions for each field\nSummarizes data type, missingness, and key statistics\n\n\n\nCode\n# Add descriptions to variables\nvar_desc &lt;- list(\n  app_id               = \"Unique identifier for each application\",\n  completion_time_mins = \"Time taken to complete the application, in minutes\",\n  household_size       = \"Number of people applying for CalFresh in the household\",\n  income               = \"Total household income in the last 30 days (randomized slightly for privacy)\",\n  docs_with_app        = \"Count of verification documents uploaded with the initial application\",\n  docs_after_app       = \"Count of verification documents uploaded after application (via Later Docs)\",\n  under18_n            = \"Number of children age 17 or younger included in the application\",\n  over_59_n            = \"Number of adults age 60 or older included in the application\",\n  stable_housing       = \"TRUE if applicant rents or owns the place they sleep; FALSE otherwise\",\n  had_interview        = \"TRUE if applicant reported completing the required interview; may be missing\",\n  zip                  = \"ZIP code where the applicant lives or stays\",\n  approved             = \"TRUE if the application was approved for CalFresh by the county\"\n)\n\n# Generate codebook\ndatabookR::databook(exercise_data, var_descriptions = var_desc)\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nVariable Description\nVariable Type\nNumber of Unique Values\nPercentage Missing\nStatistics\n\n\n\n\napp_id\nUnique identifier for each application\nnumeric\n2046\n0.0%\nMin: 1.0\nAvg: 38866.9\nMedian: 38066.5\nMax: 110550.0\nSD: 25305.4\n\n\ncompletion_time_mins\nTime taken to complete the application, in minutes\nnumeric\n2046\n0.0%\nMin: 2.3\nAvg: 21.4\nMedian: 10.4\nMax: 8551.8\nSD: 195.7\n\n\nhousehold_size\nNumber of people applying for CalFresh in the household\nnumeric\n10\n0.2%\nMin: 1.0\nAvg: 1.8\nMedian: 1.0\nMax: 12.0\nSD: 1.3\n\n\nincome\nTotal household income in the last 30 days (randomized slightly for privacy)\nnumeric\n888\n0.0%\nMin: 0.0\nAvg: 936.0\nMedian: 270.0\nMax: 9779.0\nSD: 1228.9\n\n\ndocs_with_app\nCount of verification documents uploaded with the initial application\nnumeric\n19\n0.0%\nMin: 0.0\nAvg: 1.3\nMedian: 0.0\nMax: 25.0\nSD: 2.2\n\n\ndocs_after_app\nCount of verification documents uploaded after application (via Later Docs)\nnumeric\n20\n0.0%\nMin: 0.0\nAvg: 0.8\nMedian: 0.0\nMax: 29.0\nSD: 2.1\n\n\nunder18_n\nNumber of children age 17 or younger included in the application\nnumeric\n7\n0.2%\nMin: 0.0\nAvg: 0.5\nMedian: 0.0\nMax: 6.0\nSD: 1.0\n\n\nover_59_n\nNumber of adults age 60 or older included in the application\nnumeric\n3\n0.2%\nMin: 0.0\nAvg: 0.1\nMedian: 0.0\nMax: 2.0\nSD: 0.3\n\n\nstable_housing\nTRUE if applicant rents or owns the place they sleep; FALSE otherwise\nlogical\n2\n0.0%\nTRUE: 1186 (58.0%)\nFALSE: 860 (42.0%)\n\n\nhad_interview\nTRUE if applicant reported completing the required interview; may be missing\nlogical\n2\n49.7%\nTRUE: 595 (57.8%)\nFALSE: 434 (42.2%)\n\n\nzip\nZIP code where the applicant lives or stays\nfactor\n28\n0.0%\nTop 5 Categories:\n92105 = 162 (7.9%)\n92114 = 157 (7.7%)\n92113 = 155 (7.6%)\n92115 = 133 (6.5%)\n92154 = 128 (6.3%)\n\n\napproved\nTRUE if the application was approved for CalFresh by the county\nlogical\n2\n0.0%\nTRUE: 1148 (56.1%)\nFALSE: 898 (43.9%)\n\n\nhousehold_size_bin\nDescription needed.\nfactor\n5\n0.2%\nAll Categories:\n(0,1] = 1223 (59.9%)\n(1,2] = 334 (16.4%)\n(3,5] = 228 (11.2%)\n(2,3] = 227 (11.1%)\n(5,10] = 29 (1.4%)\n\n\ndoc_group\nDescription needed.\nfactor\n4\n0.0%\nAll Categories:\nWith App Only = 797 (39.0%)\nNo Docs = 788 (38.5%)\nAfter App Only = 248 (12.1%)\nWith + After = 213 (10.4%)\n\n\n\n\n\n\n\nNotes:\n\nhad_interview has ~50% missingness, consistent with its self-reported source\nDocument counts (docs_with_app, docs_after_app) are zero-inflated and right-skewed\nOnly 4 missing values in demographic fields like household_size, under18_n, and over_59_n."
  },
  {
    "objectID": "analysis.html#missingness",
    "href": "analysis.html#missingness",
    "title": "Analysis Walkthrough",
    "section": "Missingness",
    "text": "Missingness\n\n\nCode\nvis_miss(exercise_data)\n\n\n\n\n\n\n\n\n\nOnly had_interview contains meaningful missingness. All other fields are effectively complete."
  },
  {
    "objectID": "analysis.html#distribution-of-key-variables",
    "href": "analysis.html#distribution-of-key-variables",
    "title": "Analysis Walkthrough",
    "section": "Distribution of Key Variables",
    "text": "Distribution of Key Variables\nI reviewed numeric variables to assess skew, outliers, and plausible ranges.\n\n\nCode\n# Custom binwidths for clarity\nbinwidths &lt;- list(\n  income = 250,\n  completion_time_mins = 40,\n  docs_with_app = 1,\n  docs_after_app = 1,\n  household_size = 1,\n  under18_n = 1,\n  over_59_n = 1\n)\n\n# Plotting function\n# Updated plot_var with optional filter for extreme values\nplot_var &lt;- function(var, title = NULL, max_x = NULL) {\n  data &lt;- exercise_data\n  if (!is.null(max_x)) {\n    data &lt;- data |&gt; filter(.data[[var]] &lt;= max_x)\n  }\n\n  ggplot(data, aes(.data[[var]])) +\n    geom_histogram(\n      binwidth = binwidths[[var]],\n      fill = cfa_colors$blue,\n      color = \"white\",\n      na.rm = TRUE\n    ) +\n    labs(\n      title = title %||% var,\n      x = var,\n      y = \"Count\"\n    ) +\n    theme_minimal(base_family = \"sourcesans\", base_size = 14) +\n    theme(\n      plot.title = element_text(size = 16, face = \"bold\", margin = margin(b = 10)),\n      axis.title = element_text(size = 13),\n      axis.text = element_text(size = 12)\n    )\n}\n\n\n# Generate all plots\nwrap_plots(\n  plot_var(\"income\", \"Monthly Income\"),\n  plot_var(\"completion_time_mins\", \"App Completion Time (Minutes)\", max_x = 120),\n  plot_var(\"docs_with_app\", \"Docs Uploaded With App\"),\n  plot_var(\"docs_after_app\", \"Docs Uploaded After App\"),\n  plot_var(\"household_size\", \"Household Size\"),\n  plot_var(\"under18_n\", \"Children in Household\"),\n  plot_var(\"over_59_n\", \"Older Adults in Household\"),\n  ncol = 2\n)\n\n\n\n\n\n\n\n\n\nNotes:\n\nIncome is right-skewed. Most applicants report monthly income between $0–$500, consistent with SNAP targeting.\nCompletion time clusters under 20 minutes. Outliers over 2 hours likely reflect interruptions.\nDocument fields show many zeros — many applicants do not submit documents online.\nHousehold size is small. Median = 1. Most applicants live alone or with one dependent.\nChild and older adult counts are near-zero for most, but tails exist."
  },
  {
    "objectID": "analysis.html#correlation-and-redundancy-check",
    "href": "analysis.html#correlation-and-redundancy-check",
    "title": "Analysis Walkthrough",
    "section": "Correlation and Redundancy Check",
    "text": "Correlation and Redundancy Check\nBefore building a model, I assessed relationships between predictors to check for multicollinearity.\nMulticollinearity can:\n\nInflate coefficient variance\nObscure which features are truly associated with approval\nUndermine interpretability — which is a important in this context\n\nI used two methods:\n\nPairwise correlations for numeric variables\nVariance Inflation Factor (VIF) in a preliminary logistic regression\n\n\n\nCode\n# Subset numeric predictors\nnum_vars &lt;- exercise_data |&gt;\n  select(income, household_size, under18_n, over_59_n, \n         docs_with_app, docs_after_app, completion_time_mins)\n\n# Correlation matrix\ncor_matrix &lt;- cor(num_vars, use = \"complete.obs\")\n\n# Visualize correlation matrix\ncorrplot(cor_matrix, method = \"circle\", type = \"upper\", \n         tl.cex = 0.8, tl.col = \"black\")\n\n\n\n\n\n\n\n\n\nNotes:\n\nunder18_n and household_size are moderately correlated, which is expected.\nOther variable pairs show low correlation, suggesting minimal redundancy.\n\n\n\nCode\n# Quick VIF check with basic logistic model\nvif_model &lt;- glm(\n  approved ~ income + household_size + under18_n + over_59_n +\n    docs_with_app + docs_after_app + completion_time_mins + \n    stable_housing + had_interview,\n  data = exercise_data,\n  family = binomial()\n)\n\ncar::vif(vif_model)\n\n\n              income       household_size            under18_n \n            1.570242             4.949500             4.810768 \n           over_59_n        docs_with_app       docs_after_app \n            1.082801             1.071075             1.094315 \ncompletion_time_mins       stable_housing        had_interview \n            1.012481             1.241863             1.105751 \n\n\n\nhousehold_size (4.95) and under18_n (4.81) show moderate multicollinearity — expected due to their conceptual overlap.\nAll other variables have VIFs below 2.\n\nBoth variables will likely be retained. While correlated, they reflect different eligibility factors: household size affects income limits, while the presence of children may affect processing or priority."
  },
  {
    "objectID": "analysis.html#approval-rates-by-key-variables",
    "href": "analysis.html#approval-rates-by-key-variables",
    "title": "Analysis Walkthrough",
    "section": "Approval Rates by Key Variables",
    "text": "Approval Rates by Key Variables\nTo identify process points that may shape outcomes, I calculated approval rates across key variables.\nThis helped guide feature selection and surfaced potential intervention points early.\n\n\nCode\n# Function to summarize approval rates across any categorical variable\nfnc_approval_summary &lt;- function(data, var) {\n  var_enquo &lt;- rlang::enquo(var)\n\n  summarized &lt;- data |&gt;\n    dplyr::group_by(!!var_enquo) |&gt;\n    dplyr::summarize(\n      n = dplyr::n(),\n      approval_rate = mean(approved, na.rm = TRUE),\n      .groups = \"drop\"\n    ) |&gt;\n    dplyr::mutate(approval_rate = round(approval_rate * 100, 1))\n\n  min_rate &lt;- min(summarized$approval_rate, na.rm = TRUE)\n\n  summarized |&gt;\n    gt::gt() |&gt;\n    gt::cols_label(\n      !!var_enquo := \"Group\",\n      n = \"N\",\n      approval_rate = \"Approval Rate (%)\"\n    ) |&gt;\n    gt::fmt_number(columns = n, decimals = 0) |&gt;\n    gt::tab_options(\n      table.font.names = \"Source Sans 3\",\n      column_labels.font.weight = \"bold\",\n      column_labels.background.color = \"#ece9f9\",\n      table.border.top.width = gt::px(0),\n      table.border.bottom.width = gt::px(0),\n      heading.title.font.size = 16,\n      data_row.padding = gt::px(4),\n      table.width = gt::pct(100)\n    ) |&gt;\n    gt::tab_style(\n      style = gt::cell_text(color = \"#AF121D\", weight = \"bold\"),\n      locations = gt::cells_body(\n        columns = approval_rate,\n        rows = approval_rate == min_rate\n      )\n    ) \n}"
  },
  {
    "objectID": "analysis.html#interview-completion",
    "href": "analysis.html#interview-completion",
    "title": "Analysis Walkthrough",
    "section": "Interview Completion",
    "text": "Interview Completion\n\n\nCode\nfnc_approval_summary(exercise_data, had_interview)\n\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\nFALSE\n434\n50.0\n\n\nTRUE\n595\n72.1\n\n\nNA\n1,017\n49.4\n\n\n\n\n\n\n\n\nApplicants who reported completing the interview had higher approval rates than those who did not or whose response was missing.\nThis reinforces the interview as a critical point of potential drop-off.\nMissing responses likely indicate no follow-up engagement — not necessarily ineligibility."
  },
  {
    "objectID": "analysis.html#document-submission-group",
    "href": "analysis.html#document-submission-group",
    "title": "Analysis Walkthrough",
    "section": "Document Submission Group",
    "text": "Document Submission Group\n\n\nCode\nfnc_approval_summary(exercise_data, doc_group)\n\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\nWith App Only\n797\n65.0\n\n\nAfter App Only\n248\n57.3\n\n\nWith + After\n213\n65.7\n\n\nNo Docs\n788\n44.2\n\n\n\n\n\n\n\n\nApproval was highest among applicants who submitted documents with their initial application.\nApplicants who submitted documents only after applying had moderately lower rates.\nThe lowest approval rate (~44%) was among those who submitted nothing online.\nSubmitting documents early is associated with better outcomes — possibly due to faster case processing or stronger signals of follow-through."
  },
  {
    "objectID": "analysis.html#housing-stability",
    "href": "analysis.html#housing-stability",
    "title": "Analysis Walkthrough",
    "section": "Housing Stability",
    "text": "Housing Stability\n\n\nCode\nfnc_approval_summary(exercise_data, stable_housing)\n\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\nFALSE\n860\n64.4\n\n\nTRUE\n1,186\n50.1\n\n\n\n\n\n\n\n\nSurprisingly, applicants reporting unstable housing had slightly higher approval rates.\nThis may reflect prioritized eligibility for those experiencing homelessness or precarious living situations.\nHousing instability may increase likelihood of approval due to expedited or simplified eligibility pathways."
  },
  {
    "objectID": "analysis.html#household-size-binned",
    "href": "analysis.html#household-size-binned",
    "title": "Analysis Walkthrough",
    "section": "Household Size (Binned)",
    "text": "Household Size (Binned)\n\n\nCode\nfnc_approval_summary(exercise_data, household_size_bin)\n\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\n(0,1]\n1,223\n61.7\n\n\n(1,2]\n334\n52.1\n\n\n(2,3]\n227\n45.4\n\n\n(3,5]\n228\n46.1\n\n\n(5,10]\n29\n27.6\n\n\nNA\n5\n60.0\n\n\n\n\n\n\n\n\nSmaller households (1–2 people) had the highest approval rates.\nApproval declined steadily for larger households."
  },
  {
    "objectID": "analysis.html#zip-code-variation",
    "href": "analysis.html#zip-code-variation",
    "title": "Analysis Walkthrough",
    "section": "ZIP Code Variation",
    "text": "ZIP Code Variation\nZIP code can reflect structural factors that influence access: geography, internet connectivity, support, and even worker caseloads. While it’s not causal, it helps surface system-level variation.\n\n\nCode\n# Aggregate by ZIP (filter out sparse ZIPs)\nzip_summary &lt;- exercise_data |&gt;\n  group_by(zip) |&gt;\n  summarize(\n    n = n(),\n    approval_rate = mean(approved, na.rm = TRUE)\n  ) |&gt;\n  filter(n &gt;= 10)\n\n# Bar chart\nggplot(zip_summary, aes(x = fct_reorder(zip, approval_rate), y = approval_rate)) +\n  geom_col(fill = cfa_colors$purple) +\n  coord_flip() +\n  labs(\n    title = \"Approval Rate by ZIP Code (≥10 applications)\",\n    x = \"ZIP Code\",\n    y = \"Approval Rate\"\n  ) +\n  theme_minimal(base_family = \"sourcesans\", base_size = 14) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    axis.title = element_text(size = 13),\n    axis.text = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\nNotes:\n\nApproval rates vary from ~34% to ~69% across ZIP codes.\nThis range is large enough to suggest systematic differences, not just noise.\nHigh- and low-performing ZIPs each have reasonable sample sizes, supporting this concern."
  },
  {
    "objectID": "analysis.html#statistical-test-is-zip-predictive-of-approval",
    "href": "analysis.html#statistical-test-is-zip-predictive-of-approval",
    "title": "Analysis Walkthrough",
    "section": "Statistical Test: Is ZIP Predictive of Approval?",
    "text": "Statistical Test: Is ZIP Predictive of Approval?\nTo formally assess whether approval rates differ significantly by ZIP, I ran a chi-squared test:\n\n\nCode\nzip_test &lt;- exercise_data |&gt;\n  filter(!is.na(approved), !is.na(zip)) |&gt;\n  count(zip, approved) |&gt;\n  pivot_wider(names_from = approved, values_from = n, values_fill = 0) |&gt;\n  column_to_rownames(\"zip\") |&gt;\n  as.matrix() |&gt;\n  chisq.test()\n\nzip_test\n\n\n\n    Pearson's Chi-squared test\n\ndata:  as.matrix(column_to_rownames(pivot_wider(count(filter(exercise_data,     !is.na(approved), !is.na(zip)), zip, approved), names_from = approved,     values_from = n, values_fill = 0), \"zip\"))\nX-squared = 43.85, df = 27, p-value = 0.02143\n\n\nInterpretation:\n\nThe test is statistically significant at the 5% level.\nWe reject the null hypothesis: approval rates differ by ZIP in a non-random way.\nThis supports using ZIP as a signal for access disparities — even in the absence of ACS or other geospatial data."
  },
  {
    "objectID": "analysis.html#variable-preparation-for-modeling",
    "href": "analysis.html#variable-preparation-for-modeling",
    "title": "Analysis Walkthrough",
    "section": "Variable Preparation for Modeling",
    "text": "Variable Preparation for Modeling\nBefore modeling, I transformed several variables to improve interpretability, address skew, and reflect real-world program logic. These decisions were based on exploratory analysis and domain context from CalFresh eligibility and the GetCalFresh user flow.\n\nIncome\n\nCreated a new variable `income_500, which scales income in units of $500 for more interpretable model coefficients.\nExample: A coefficient of –0.3 now means a 1-point drop in approval odds per $500 increase in monthly income.\n\n\n\nCode\nexercise_data &lt;- exercise_data |&gt;\n  mutate(income_500 = income / 500)\n\n\n\n\nApplication Completion Time\n\nCapped extreme values above 180 minutes to reduce the influence of long-tail outliers.\nCreated a binary flag long_app for applications that took over one hour, which may indicate interruptions or complexity.\n\n\n\nCode\nexercise_data &lt;- exercise_data |&gt;\n  mutate(\n    completion_time_capped = if_else(completion_time_mins &gt; 180, 180, completion_time_mins),\n    long_app = completion_time_mins &gt; 60\n  )\n\n\n\n\nDocument Uploads\n\nCreated total_docs to capture total documentation effort across both stages (with and after application).\nAdded a binned version total_docs_bin to explore non-linear patterns in document count and approval.\n\n\n\nCode\nexercise_data &lt;- exercise_data |&gt;\n  mutate(\n    total_docs = docs_with_app + docs_after_app,\n    total_docs_bin = case_when(\n      total_docs == 0 ~ \"0\",\n      total_docs &lt;= 2 ~ \"1–2\",\n      total_docs &lt;= 5 ~ \"3–5\",\n      TRUE ~ \"6+\"\n    ) |&gt; factor(levels = c(\"0\", \"1–2\", \"3–5\", \"6+\"))\n  )\n\n\n\n\nInterview Completion (Self-Reported)\n\nRe-coded had_interview into a two-level categorical variable, interview_completed:\n“Completed” if applicant responded “yes” via SMS\n“Not confirmed” for both “no” and missing, since missing likely means no engagement\n\n\n\nCode\nexercise_data &lt;- exercise_data |&gt;\n  mutate(interview_completed = case_when(\n    had_interview == TRUE ~ \"Completed\",\n    TRUE ~ \"Not confirmed\"\n  ) |&gt; factor(levels = c(\"Not confirmed\", \"Completed\")))\n\n\nThese transformations prepare the dataset for modeling while maintaining interpretability for stakeholders."
  },
  {
    "objectID": "analysis.html#variable-selection-rationale",
    "href": "analysis.html#variable-selection-rationale",
    "title": "Analysis Walkthrough",
    "section": "Variable Selection Rationale",
    "text": "Variable Selection Rationale\nVariables were selected based on relevance to both CalFresh policy and user experience. The model includes:\n\nEligibility criteria: income, household size, number of children, number of older adults\nUser actions: whether documents were submitted (with or after the application), whether the interview was completed\nProcess indicators: time spent on the application, housing stability\n\nI created and tested multiple versions of several predictors (e.g., binned document counts, total documentation effort, binary flags for long application times) and retained only the most interpretable versions for the main model. These alternate variables are available for subgroup or follow-up analyses."
  },
  {
    "objectID": "analysis.html#model-specification",
    "href": "analysis.html#model-specification",
    "title": "Analysis Walkthrough",
    "section": "Model Specification",
    "text": "Model Specification\n\n\nCode\napproval_model &lt;- glm(\n  approved ~ income_500 + household_size + under18_n + over_59_n +\n    docs_with_app + docs_after_app + completion_time_capped +\n    stable_housing + interview_completed,\n  data = exercise_data,\n  family = binomial()\n)\n\nsummary(approval_model)\n\n\n\nCall:\nglm(formula = approved ~ income_500 + household_size + under18_n + \n    over_59_n + docs_with_app + docs_after_app + completion_time_capped + \n    stable_housing + interview_completed, family = binomial(), \n    data = exercise_data)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                   0.628432   0.131272   4.787 1.69e-06 ***\nincome_500                   -0.412618   0.029816 -13.839  &lt; 2e-16 ***\nhousehold_size               -0.125768   0.088893  -1.415  0.15712    \nunder18_n                     0.300545   0.117048   2.568  0.01024 *  \nover_59_n                     0.121020   0.155961   0.776  0.43777    \ndocs_with_app                 0.116576   0.025326   4.603 4.16e-06 ***\ndocs_after_app                0.075872   0.027076   2.802  0.00507 ** \ncompletion_time_capped       -0.001958   0.002632  -0.744  0.45674    \nstable_housingTRUE           -0.086942   0.112313  -0.774  0.43887    \ninterview_completedCompleted  1.098309   0.118276   9.286  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2800.1  on 2041  degrees of freedom\nResidual deviance: 2373.5  on 2032  degrees of freedom\n  (4 observations deleted due to missingness)\nAIC: 2393.5\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nCoefficient Interpretation\nThis logistic regression estimates the change in log-odds of approval for each predictor, holding other variables constant.\nKey observations:\n\nincome_500: Strong and statistically significant. A $500 increase in income is associated with a 0.41 decrease in the log-odds of approval (p &lt; 0.001).\ninterview_completedCompleted: The largest effect. Completing the interview increases the log-odds of approval by 1.10, a strong and highly significant association (p &lt; 0.001).\ndocs_with_app and docs_after_app: Both are positive and significant. More documents are associated with higher approval odds, especially those submitted with the application.\nunder18_n: Also significant. Each additional child increases log-odds of approval by 0.30.\nhousehold_size, over_59_n, completion_time_capped, and stable_housing are not statistically significant (all p &gt; 0.05) and show small effects.\n\nThis means that once income, documentation, and interview completion are accounted for, these other variables do not explain meaningful additional variation in approval likelihood."
  },
  {
    "objectID": "analysis.html#odds-ratios-and-confidence-intervals",
    "href": "analysis.html#odds-ratios-and-confidence-intervals",
    "title": "Analysis Walkthrough",
    "section": "Odds Ratios and Confidence Intervals",
    "text": "Odds Ratios and Confidence Intervals\n\n\nCode\nmodel_results &lt;- broom::tidy(approval_model, exponentiate = TRUE, conf.int = TRUE)\n\nmodel_results |&gt;\n  select(term, estimate, conf.low, conf.high, p.value) |&gt;\n  mutate(across(where(is.numeric), round, 2)) |&gt;\n  gt::gt() |&gt;\n  gt::cols_label(\n    term = \"Variable\",\n    estimate = \"Odds Ratio\",\n    conf.low = \"95% CI (Low)\",\n    conf.high = \"95% CI (High)\",\n    p.value = \"P-Value\"\n  ) |&gt;\n  gt::tab_options(\n    table.font.names = \"Source Sans 3\",\n    heading.title.font.size = 16\n  )\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.numeric), round, 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n\n\n\n\n\n\nVariable\nOdds Ratio\n95% CI (Low)\n95% CI (High)\nP-Value\n\n\n\n\n(Intercept)\n1.87\n1.45\n2.43\n0.00\n\n\nincome_500\n0.66\n0.62\n0.70\n0.00\n\n\nhousehold_size\n0.88\n0.74\n1.05\n0.16\n\n\nunder18_n\n1.35\n1.07\n1.70\n0.01\n\n\nover_59_n\n1.13\n0.83\n1.53\n0.44\n\n\ndocs_with_app\n1.12\n1.07\n1.18\n0.00\n\n\ndocs_after_app\n1.08\n1.02\n1.14\n0.01\n\n\ncompletion_time_capped\n1.00\n0.99\n1.00\n0.46\n\n\nstable_housingTRUE\n0.92\n0.74\n1.14\n0.44\n\n\ninterview_completedCompleted\n3.00\n2.38\n3.79\n0.00\n\n\n\n\n\n\n\n\nOdds Ratio Interpretation\n\nInterview Completed\nApplicants who completed the interview had 3x higher odds of approval — the strongest predictor.\nIncome\nEvery $500 increase in income reduced approval odds by 34%, reflecting income-based eligibility rules.\nDocuments Submitted With Application\nEach additional document uploaded with the application increased approval odds by 12%.\nDocuments Submitted After Application\nStill helpful — associated with an 8% increase in approval odds per document.\nChildren in Household\nEach additional child increased approval odds by 35%, likely due to eligibility prioritization.\nNot Significant\nHousehold size, older adults, time to complete application, and housing status did not show meaningful associations after controlling for other factors."
  },
  {
    "objectID": "analysis.html#diagnostics",
    "href": "analysis.html#diagnostics",
    "title": "Analysis Walkthrough",
    "section": "Diagnostics",
    "text": "Diagnostics\nAfter fitting the logistic regression, I ran several checks to evaluate how well the model fits the data and whether the results are trustworthy. These diagnostics focus on:\n\nHow much variation the model explains\nWhether predicted probabilities align with actual outcomes\nHow well the model distinguishes approved vs. denied applications\n\n1. McFadden’s Psuedo R²\nDefinition: A measure of how much better the model fits the data compared to a model with no predictors (just an intercept).\n\n# Pseudo R-squared\npscl::pR2(approval_model)\n\nfitting null model for pseudo-r2\n\n\n          llh       llhNull            G2      McFadden          r2ML \n-1186.7634616 -1400.0644571   426.6019909     0.1523508     0.1885348 \n         r2CU \n    0.2526548 \n\n\nThe pseudo R² was around 0.15, which indicates a moderate effect size. That’s typical in behavioral data, where many influencing factors aren’t captured in the dataset.\n2. Hosmer–Lemeshow Goodness-of-Fit Test\nThis test checks whether the model’s predicted probabilities align with the actual outcomes. It groups observations into deciles by predicted probability, then compares predicted vs. actual approval rates in each group.\n\nhoslem.test(approval_model$y, fitted(approval_model))\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  approval_model$y, fitted(approval_model)\nX-squared = 9.0452, df = 8, p-value = 0.3385\n\n\nOur p-value is 0.34, which is not staistically significant. That’s good — it means there’s no evidence of poor fit. The model’s predictions are consistent with observed data.\n3. ROC Curve and AUC (Area Under the Curve)\nAUC summarizes how well the model distinguishes between approved and denied applicants.\n\nmodel_data &lt;- model.frame(approval_model)\nactual &lt;- model_data$approved\npredicted &lt;- fitted(approval_model)\n\nroc_obj &lt;- roc(actual, predicted)\nplot(roc_obj, col = cfa_colors$blue, lwd = 2)\n\n\n\n\n\n\n\npROC::auc(roc_obj)\n\nArea under the curve: 0.7563\n\n\nInterpretation:\n\nAUC = 0.76 means the model assigns a higher predicted probability to an approved case than a denied one 76% of the time.\nThat’s considered good performance for a logistic model using only observable application behaviors.\n\nTogether, these diagnostics show that the model is well-calibrated, explains meaningful variation, and performs reliably — even with known limitations in the dataset.\n4. Train/Test Split\nTo evaluate how well the model generalizes, I randomly split the data into:\n\n80% training set (used to fit the model)\n20% test set (used to evaluate performance on unseen data)\n\nThe model was re-fit on the training set, and predicted approval probabilities were generated for the test set. AUC was then calculated on these out-of-sample predictions.\n\nset.seed(42)\n\n# Split the data\ntrain_idx &lt;- sample(seq_len(nrow(exercise_data)), size = 0.8 * nrow(exercise_data))\ntrain_data &lt;- exercise_data[train_idx, ]\ntest_data  &lt;- exercise_data[-train_idx, ]\n\n# Refit model on training set\napproval_model &lt;- glm(\n  approved ~ income_500 + household_size + under18_n + over_59_n +\n    docs_with_app + docs_after_app + completion_time_capped +\n    stable_housing + interview_completed,\n  data = train_data,\n  family = binomial()\n)\n\n# Predict on test set\ntest_data &lt;- test_data |&gt;\n  mutate(predicted_prob = predict(approval_model, newdata = test_data, type = \"response\"))\n\n# AUC on test data\nroc_test &lt;- roc(test_data$approved, test_data$predicted_prob)\nauc(roc_test)\n\nArea under the curve: 0.7465\n\n\nInterpretation:\n\nAUC on the test set = 0.76, nearly identical to the in-sample AUC.\nThe model performs consistently on new data.\nThere is no sign of overfitting, and the results generalize well to similar applicants."
  },
  {
    "objectID": "analysis.html#example-effect-of-interview-completion",
    "href": "analysis.html#example-effect-of-interview-completion",
    "title": "Analysis Walkthrough",
    "section": "Example: Effect of Interview Completion",
    "text": "Example: Effect of Interview Completion\n\n\nCode\nmodel_data |&gt;\n  group_by(interview_completed) |&gt;\n  summarize(mean_pred_prob = round(mean(predicted_prob), 2), n = n())\n\n\n# A tibble: 2 × 3\n  interview_completed mean_pred_prob     n\n  &lt;fct&gt;                        &lt;dbl&gt; &lt;int&gt;\n1 Not confirmed                 0.5   1447\n2 Completed                     0.72   595\n\n\n\nApplicants who completed the interview had a 72% average chance of being approved.\nThose who did not complete or did not confirm the interview had just a 50% chance.\nThis 22 percentage point difference shows how critical the interview step is.\nSupporting applicants through the interview process — with reminders, assistance, or flexible scheduling — could meaningfully improve approval rates."
  },
  {
    "objectID": "key_findings.html",
    "href": "key_findings.html",
    "title": "Key Findings",
    "section": "",
    "text": "This analysis examines 2,046 CalFresh applications submitted via GetCalFresh.org in San Diego County. The goal was to understand which factors are most strongly associated with approval outcomes and where the process might be improved to better serve eligible applicants."
  },
  {
    "objectID": "key_findings.html#support-interview-completion",
    "href": "key_findings.html#support-interview-completion",
    "title": "Key Findings",
    "section": "1. Support interview completion",
    "text": "1. Support interview completion\nThe interview is required for approval, but many applicants don’t complete it. The gap in approval rates between those who did and didn’t is over 20 percentage points.\nBarriers may include: missed calls, unclear instructions, or timing issues.\nPotential solutions: more flexible scheduling, clearer SMS reminders, or helping applicants understand that the interview is required."
  },
  {
    "objectID": "key_findings.html#encourage-early-document-uploads",
    "href": "key_findings.html#encourage-early-document-uploads",
    "title": "Key Findings",
    "section": "2. Encourage early document uploads",
    "text": "2. Encourage early document uploads\nUploading documents with the application is linked to much higher approval rates. But many applicants submit no documents online.\nBarriers may include: not knowing which documents are needed, technical issues, or thinking it can wait. Potential solutions: adding optional upload prompts in the application flow, providing examples of helpful documents, or follow-up nudges after submission.\nThese insights point to concrete ways to improve the user experience and approval outcomes without changing eligibility rules."
  },
  {
    "objectID": "key_findings.html#key-findings-for-stakeholders",
    "href": "key_findings.html#key-findings-for-stakeholders",
    "title": "Key Findings",
    "section": "Key Findings for Stakeholders",
    "text": "Key Findings for Stakeholders\n\nCompleting the required interview was the strongest factor. Applicants who completed it had a 72% chance of approval, compared to 50% for those who didn’t or didn’t respond.\nUploading documents early was linked to higher approval. Applicants who submitted documents with their application were more likely to be approved than those who submitted none. Uploading documents after applying helped somewhat, but not as much.\nLower income was slightly associated with higher approval, reflecting eligibility thresholds. However, the effect was smaller than other process-related factors.\nHaving children was associated with higher approval. Each additional child increased the likelihood of being approved.\nOther factors — like housing stability, household size, and older adults in the household — were not strongly linked to approval once other variables were taken into account.\n\nNote: The logistic model had good overall performance (AUC = 0.76; Hosmer-Lemeshow p = 0.34). It focused on variables observed during application submission to prioritize transparency and real-world relevance."
  },
  {
    "objectID": "key_findings.html#what-factors-are-most-strongly-associated-with-calfresh-approval",
    "href": "key_findings.html#what-factors-are-most-strongly-associated-with-calfresh-approval",
    "title": "Key Findings",
    "section": "What factors are most strongly associated with CalFresh approval?",
    "text": "What factors are most strongly associated with CalFresh approval?"
  },
  {
    "objectID": "key_findings.html#where-would-i-look-next",
    "href": "key_findings.html#where-would-i-look-next",
    "title": "Key Findings",
    "section": "Where would I look next?",
    "text": "Where would I look next?\nBased on this analysis, two areas seem promising for improving access and reducing unnecessary denials:\n\n1. Support interview completion\nThe interview is required for approval, but many applicants don’t complete it. The gap in approval rates between those who did and didn’t is over 20 percentage points.\nBarriers may include: missed calls, unclear instructions, or timing issues.\nPotential solutions: more flexible scheduling, clearer SMS reminders, or helping applicants understand that the interview is required.\n\n\n2. Encourage early document uploads\nUploading documents with the application is linked to much higher approval rates. But many applicants submit no documents online.\nBarriers may include: not knowing which documents are needed, technical issues, or thinking it can wait. Potential solutions: adding optional upload prompts in the application flow, providing examples of helpful documents, or follow-up nudges after submission.\nThese insights point to concrete ways to improve the user experience and approval outcomes without changing eligibility rules."
  },
  {
    "objectID": "key_findings.html#output-table",
    "href": "key_findings.html#output-table",
    "title": "Key Findings",
    "section": "Output Table",
    "text": "Output Table\nTBD\n\n2. Based on your results, where would you look next in terms of identifying potential improvements to the application?\nImproving the Application Process: Streamlining Document Uploads and Reassessing the Interview Requirement\nBased on the findings, two key areas emerge as crucial for improving the CalFresh application process.\nFirst, document submission is essential to the approval process. Applicants who uploaded documents with their application were much more likely to be approved. However, many applicants did not upload any documents, which likely delayed their application or led to denials. Addressing barriers to document submission, such as clarifying which documents are required and providing prompts to upload them during the application process, could improve approval rates. Additionally, implementing follow-up reminders or prompts to upload missing documents could help ensure that applicants complete this crucial step.\nSecond, the interview step may be an area for improvement. Given that completing the interview is strongly associated with higher approval rates, it would be beneficial to investigate barriers to completing the interview, such as missed calls, unclear instructions, or scheduling conflicts. However, an alternative solution could be to reconsider the interview requirement altogether, especially for applicants who have provided all necessary documentation. Streamlining the process by eliminating the interview requirement for these cases could reduce unnecessary drop-off and help speed up approvals, ensuring that eligible applicants are not penalized for logistical reasons."
  },
  {
    "objectID": "analysis.html#implications-for-the-data",
    "href": "analysis.html#implications-for-the-data",
    "title": "Analysis",
    "section": "Implications for the Data",
    "text": "Implications for the Data\nThis walkthrough shaped how I interpret key variables:\n\nhad_interview is self-reported via SMS. Missing values likely mean no follow-up, not just missing data.\ndocs_with_app vs. docs_after_app show when documents were uploaded through GetCalFresh — not whether the county eventually received them.\ncompletion_time_mins may reflect time spent across multiple sessions, interruptions, or technical issues — not necessarily user motivation."
  },
  {
    "objectID": "analysis.html#key-variables",
    "href": "analysis.html#key-variables",
    "title": "Analysis",
    "section": "Key Variables",
    "text": "Key Variables\n\n\n\n\n\n\n\n\nVariable\nWhat it captures\nNotes\n\n\n\n\nincome\nHousehold income in the last 30 days\nRandomized slightly for privacy\n\n\nhousehold_size\nNumber of people applying\nDrives income eligibility\n\n\ndocs_with_app\nDocuments uploaded at time of application\nOptional at this stage\n\n\ndocs_after_app\nDocuments uploaded later via GetCalFresh\nOften happens after interview\n\n\nhad_interview\nSelf-reported response to an SMS\nMissing ≠ no interview\n\n\ncompletion_time_mins\nTime from start to submission\nCan include breaks or re-entries\n\n\nstable_housing\nWhether the applicant rents/owns their sleeping location\nReflects housing security\n\n\nunder18_n, over_59_n\nCount of children or older adults in household\nCould affect prioritization\n\n\nzip\nZIP code of applicant\nMay reflect geographic barriers\n\n\napproved\nFinal outcome (TRUE = approved)\nProvided by the county"
  },
  {
    "objectID": "analysis.html#important-context",
    "href": "analysis.html#important-context",
    "title": "Analysis",
    "section": "Important Context",
    "text": "Important Context"
  },
  {
    "objectID": "analysis.html#application-walkthrough",
    "href": "analysis.html#application-walkthrough",
    "title": "Analysis Walkthrough",
    "section": "Application Walkthrough",
    "text": "Application Walkthrough\nBefore analyzing the data, I walked through the GetCalFresh.org application process myself. This helped clarify how each field is presented to applicants, what steps are required or optional, and where friction might arise.\n\n\n\nCalFresh Survey Image\n\n\nSeeing the application from a user’s perspective provided critical context for interpreting the dataset — especially for process-related variables like document uploads, interview completion, and application duration.\n\nKey Takeaways\n\nMultilingual support is available early in the application (English, Spanish, Chinese, Vietnamese), with additional language preferences captured later.\nThe application is structured in stages: household info → income → expenses → contact details → confirmation.\nApplicants get real-time feedback about possible eligibility and whether they might qualify for expedited processing.\nDocument uploads and interviews aren’t required at submission — they can happen later, which means missing data doesn’t always signal ineligibility.\nToward the end, applicants confirm contact information, set preferences (e.g., language, reminders), and indicate interview availability.\n\nThis walkthrough was useful for interpreting behavioral data in context — especially steps that are optional, delayed, or invisible in the dataset (like phone interviews completed outside the platform)."
  },
  {
    "objectID": "analysis.html#about-the-data",
    "href": "analysis.html#about-the-data",
    "title": "Analysis Walkthrough",
    "section": "About the Data",
    "text": "About the Data\nThis dataset includes 2,046 CalFresh (SNAP) applications submitted through GetCalFresh.org in San Diego County. Each row represents one application and contains:\n\nInformation reported by the applicant\nActivity tracked through the GetCalFresh platform\nFinal approval outcome provided by the county\n\nThe dataset reflects the user-facing side of the process. It does not capture every factor a county worker might see (e.g., paper documents or offline interviews), but it provides a detailed view of what users did on the site and what happened afterward.\nKey Variables\n\n\n\n\n\n\n\n\nVariable\nDescription\nNotes\n\n\n\n\nincome\nHousehold income in the last 30 days\nSlightly randomized for privacy\n\n\nhousehold_size\nNumber of people applying\nUsed to determine income thresholds\n\n\ndocs_with_app\nDocuments uploaded with the application\nOptional at time of submission\n\n\ndocs_after_app\nDocuments uploaded after submission\nOften submitted after the interview\n\n\nhad_interview\nApplicant’s self-report of completing the interview\nBased on SMS follow-up; may be missing\n\n\ncompletion_time_mins\nTime taken to complete the application\nMay include pauses or returns\n\n\nstable_housing\nWhether applicant rents/owns their sleeping location\nProxy for housing stability\n\n\nunder18_n, over_59_n\nChildren or older adults in the household\nMay influence prioritization or eligibility\n\n\nzip\nApplicant ZIP code\nMay reflect local conditions or access issues\n\n\napproved\nFinal approval outcome\nProvided by the county\n\n\n\nContextual Notes:\n\nInterview completion (had_interview) comes from an SMS response. Missing values do not confirm whether an interview occurred — only that no reply was recorded.\nDocument fields only include uploads through GetCalFresh. Submissions made by mail, fax, or in person are not tracked here.\nApproval decisions come from county records and represent real outcomes.\n\nUnderstanding what’s captured — and what’s missing — helped guide how I handled missingness and interpreted variables."
  },
  {
    "objectID": "analysis.html#exploratory-data-analysis",
    "href": "analysis.html#exploratory-data-analysis",
    "title": "Analysis Walkthrough",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nBefore modeling, I conducted an exploratory analysis to:\n\nUnderstand the distribution and structure of each variable\nIdentify missingness and data quality issues\nSpot early signals related to approval\nPrepare features for interpretability and modeling\n\n\nCodebook Summary\nI created a structured codebook using a function from my own databookR package. It describes each variable, its type, missingness, and key statistics — and forms the foundation for all further steps.\n\n# Add descriptions to variables\nvar_desc &lt;- list(\n  app_id               = \"Unique identifier for each application\",\n  completion_time_mins = \"Time taken to complete the application, in minutes\",\n  household_size       = \"Number of people applying for CalFresh in the household\",\n  income               = \"Total household income in the last 30 days (randomized slightly for privacy)\",\n  docs_with_app        = \"Count of verification documents uploaded with the initial application\",\n  docs_after_app       = \"Count of verification documents uploaded after application (via Later Docs)\",\n  under18_n            = \"Number of children age 17 or younger included in the application\",\n  over_59_n            = \"Number of adults age 60 or older included in the application\",\n  stable_housing       = \"TRUE if applicant rents or owns the place they sleep; FALSE otherwise\",\n  had_interview        = \"TRUE if applicant reported completing the required interview; may be missing\",\n  zip                  = \"ZIP code where the applicant lives or stays\",\n  approved             = \"TRUE if the application was approved for CalFresh by the county\"\n)\n\n# Generate databook\ndatabookR::databook(exercise_data, var_descriptions = var_desc)\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nVariable Description\nVariable Type\nNumber of Unique Values\nPercentage Missing\nStatistics\n\n\n\n\napp_id\nUnique identifier for each application\nnumeric\n2046\n0.0%\nMin: 1.0\nAvg: 38866.9\nMedian: 38066.5\nMax: 110550.0\nSD: 25305.4\n\n\ncompletion_time_mins\nTime taken to complete the application, in minutes\nnumeric\n2046\n0.0%\nMin: 2.3\nAvg: 21.4\nMedian: 10.4\nMax: 8551.8\nSD: 195.7\n\n\nhousehold_size\nNumber of people applying for CalFresh in the household\nnumeric\n10\n0.2%\nMin: 1.0\nAvg: 1.8\nMedian: 1.0\nMax: 12.0\nSD: 1.3\n\n\nincome\nTotal household income in the last 30 days (randomized slightly for privacy)\nnumeric\n888\n0.0%\nMin: 0.0\nAvg: 936.0\nMedian: 270.0\nMax: 9779.0\nSD: 1228.9\n\n\ndocs_with_app\nCount of verification documents uploaded with the initial application\nnumeric\n19\n0.0%\nMin: 0.0\nAvg: 1.3\nMedian: 0.0\nMax: 25.0\nSD: 2.2\n\n\ndocs_after_app\nCount of verification documents uploaded after application (via Later Docs)\nnumeric\n20\n0.0%\nMin: 0.0\nAvg: 0.8\nMedian: 0.0\nMax: 29.0\nSD: 2.1\n\n\nunder18_n\nNumber of children age 17 or younger included in the application\nnumeric\n7\n0.2%\nMin: 0.0\nAvg: 0.5\nMedian: 0.0\nMax: 6.0\nSD: 1.0\n\n\nover_59_n\nNumber of adults age 60 or older included in the application\nnumeric\n3\n0.2%\nMin: 0.0\nAvg: 0.1\nMedian: 0.0\nMax: 2.0\nSD: 0.3\n\n\nstable_housing\nTRUE if applicant rents or owns the place they sleep; FALSE otherwise\nlogical\n2\n0.0%\nTRUE: 1186 (58.0%)\nFALSE: 860 (42.0%)\n\n\nhad_interview\nTRUE if applicant reported completing the required interview; may be missing\nlogical\n2\n49.7%\nTRUE: 595 (57.8%)\nFALSE: 434 (42.2%)\n\n\nzip\nZIP code where the applicant lives or stays\nfactor\n28\n0.0%\nTop 5 Categories:\n92105 = 162 (7.9%)\n92114 = 157 (7.7%)\n92113 = 155 (7.6%)\n92115 = 133 (6.5%)\n92154 = 128 (6.3%)\n\n\napproved\nTRUE if the application was approved for CalFresh by the county\nlogical\n2\n0.0%\nTRUE: 1148 (56.1%)\nFALSE: 898 (43.9%)\n\n\n\n\n\n\n\nNotable Patterns:\n\nIncome is low for most applicants (median = $270/month).\nApplication time is short (median = 10 minutes), but some outliers take hours.\nMost users submit no documents online, even after applying.\nInterview data is missing for more than half — not necessarily because no interview occurred.\nApproval rate = 56%, giving enough variation for modeling.\n\nThis codebook gave me a clear view of how people move through the process. It highlighted variables with missing or unusual values, flagged behaviors worth looking into (like how few applicants upload documents or report completing interviews), and pointed to patterns that might be important for understanding who gets approved.\n\n\nMissingness\nTo assess data quality, I visualized missingness across all variables using vis_miss().\n\nvis_miss(exercise_data)\n\n\n\n\n\n\n\n\nOnly had_interview has meaningful missing data (~50%). All other fields are complete or nearly complete. This missingness is expected — the interview variable comes from a follow-up SMS survey, and not all applicants respond.\n\n\nDistribution of Key Variables\nI next reviewed distributions of numeric variables to check for skew, outliers, and interpretability issues.\n\n# Custom binwidths\nbinwidths &lt;- list(\n  income = 250,\n  completion_time_mins = 40,\n  docs_with_app = 1,\n  docs_after_app = 1,\n  household_size = 1,\n  under18_n = 1,\n  over_59_n = 1\n)\n\n# Generate all plots\nwrap_plots(\n  fnc_plot_var(\"income\", \"Monthly Income\"),\n  fnc_plot_var(\"completion_time_mins\", \"App Completion Time (Minutes)\", max_x = 120),\n  fnc_plot_var(\"docs_with_app\", \"Docs Uploaded With App\"),\n  fnc_plot_var(\"docs_after_app\", \"Docs Uploaded After App\"),\n  fnc_plot_var(\"household_size\", \"Household Size\"),\n  fnc_plot_var(\"under18_n\", \"Children in Household\"),\n  fnc_plot_var(\"over_59_n\", \"Older Adults in Household\"),\n  ncol = 2\n)\n\n\n\n\n\n\n\n\nObservations:\n\nIncome is heavily right-skewed. Most applicants report less than $500/month.\nCompletion time clusters below 20 minutes. A few outliers extend far beyond that range.\nDocument uploads: The majority of applicants upload no documents at all, either before or after applying.\nHousehold size: Most applicants apply alone or with one other person.\nChildren and older adults: Most applications list zero dependents under 18 or over 59.\n\nThese patterns suggest that most applicants are low-income, likely applying alone, and often do not upload documents upfront — all of which could influence approval outcomes.\n\n\nCorrelation and Redundancy Check\nBefore modeling, I examined relationships among predictors to identify potential multicollinearity or redundancy. This ensures that coefficients remain stable and interpretable.\nMethod 1: Correlation Matrix\nI computed pairwise correlations among numeric variables:\n\n# Select numeric predictors\nnum_vars &lt;- exercise_data |&gt;\n  select(income, household_size, under18_n, over_59_n, \n         docs_with_app, docs_after_app, completion_time_mins)\n\n# Compute correlations\ncor_matrix &lt;- cor(num_vars, use = \"complete.obs\")\n\n# Visualize\ncorrplot(cor_matrix, method = \"circle\", type = \"upper\", \n         tl.cex = 0.8, tl.col = \"black\",\n         col = colorRampPalette(c(cfa_colors$red, \"white\", cfa_colors$blue))(200))\n\n\n\n\n\n\n\n\nInterpretation:\n\nunder18_n and household_size are moderately correlated (makes sense — families with children are larger).\nAll other variables are weakly correlated.\nNo pairs appear highly redundant.\n\nMethod 2: Variance Inflation Factor (VIF)\nI fit a preliminary logistic regression model to compute VIFs:\n\n# Quick VIF check with basic logistic model\nvif_model &lt;- glm(\n  approved ~ income + household_size + under18_n + over_59_n +\n    docs_with_app + docs_after_app + completion_time_mins + \n    stable_housing + had_interview,\n  data = exercise_data,\n  family = binomial()\n)\n\ncar::vif(vif_model)\n\n              income       household_size            under18_n \n            1.570242             4.949500             4.810768 \n           over_59_n        docs_with_app       docs_after_app \n            1.082801             1.071075             1.094315 \ncompletion_time_mins       stable_housing        had_interview \n            1.012481             1.241863             1.105751 \n\n\n\nhousehold_size (4.95) and under18_n (4.81) show moderate multicollinearity — expected due to their conceptual overlap.\nAll other variables have VIFs below 2.\n\nBoth variables household_size and under18_n, will likely be retained. While correlated, they reflect different eligibility factors: household size affects income limits, while the presence of children may affect processing or priority.\n\n\nApproval Rates by Key Variables\nTo understand where in the process outcomes start to diverge, I looked at approval rates across key variables. This helped identify patterns worth modeling and showed possible intervention points.\n\n\nInterview Completion\n\nfnc_approval_summary(exercise_data, had_interview)\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\nFALSE\n434\n50.0\n\n\nTRUE\n595\n72.1\n\n\nNA\n1,017\n49.4\n\n\n\n\n\n\n\n\nApplicants who reported completing the interview had higher approval rates than those who did not or whose response was missing.\nThis reinforces the interview as a critical point of potential drop-off.\nMissing responses likely indicate no follow-up engagement — not necessarily ineligibility.\n\n\n\nDocument Submission Group\nI grouped applicants by when (or whether) they submitted documents:\n\n# Add a doc_group variable \nexercise_data &lt;- exercise_data |&gt; \n  mutate(\n    doc_group = case_when(\n        docs_with_app &gt; 0 & docs_after_app == 0 ~ \"With App Only\",\n        docs_with_app == 0 & docs_after_app &gt; 0 ~ \"After App Only\",\n        docs_with_app &gt; 0 & docs_after_app &gt; 0 ~ \"With + After\",\n        docs_with_app == 0 & docs_after_app == 0 ~ \"No Docs\"\n        ) |&gt; \n      factor(levels = c(\"With App Only\", \"After App Only\", \"With + After\", \"No Docs\"))\n      )\nfnc_approval_summary(exercise_data, doc_group)\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\nWith App Only\n797\n65.0\n\n\nAfter App Only\n248\n57.3\n\n\nWith + After\n213\n65.7\n\n\nNo Docs\n788\n44.2\n\n\n\n\n\n\n\n\nApproval was highest among applicants who submitted documents with their initial application.\nApplicants who submitted documents only after applying had moderately lower rates.\nThe lowest approval rate (~44%) was among those who submitted nothing online.\n\nThis suggests that early document submission may signal follow-through — or speed up processing.\n\n\nHousing Stability\n\nfnc_approval_summary(exercise_data, stable_housing)\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\nFALSE\n860\n64.4\n\n\nTRUE\n1,186\n50.1\n\n\n\n\n\n\n\n\nApplicants reporting unstable housing had higher approval rates.\nThis may reflect prioritized eligibility for those experiencing housing instability.\nHousing instability may increase likelihood of approval due to expedited or simplified eligibility pathways.\n\n\n\nHousehold Size (Binned)\nI binned household size for interpretability:\n\n# Add bins\nexercise_data &lt;- exercise_data |&gt; \n  mutate(household_size_bin = cut(household_size, breaks = c(0,1,2,3,5,10)))\n\nfnc_approval_summary(exercise_data, household_size_bin)\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\n(0,1]\n1,223\n61.7\n\n\n(1,2]\n334\n52.1\n\n\n(2,3]\n227\n45.4\n\n\n(3,5]\n228\n46.1\n\n\n(5,10]\n29\n27.6\n\n\nNA\n5\n60.0\n\n\n\n\n\n\n\n\n1–2 person households had the highest approval rates.\nLarger households saw lower approval rates.\nThis may be due to stricter income thresholds at higher household sizes — or more complexity in verifying eligibility.\n\n\n\nZIP Code Variation\nZIP code can reflect structural factors that influence access: geography, internet connectivity, support, and even worker caseloads. While it’s not causal, it helps show system-level variation.\nI assessed variation in approval rates by ZIP code, filtering out ZIPs with fewer than 10 applications:\n\n# Aggregate by ZIP (filter out sparse ZIPs)\nzip_summary &lt;- exercise_data |&gt;\n  group_by(zip) |&gt;\n  summarize(\n    n = n(),\n    approval_rate = mean(approved, na.rm = TRUE)\n  ) |&gt;\n  filter(n &gt;= 10)\n\n# Bar chart\nggplot(zip_summary, aes(x = fct_reorder(zip, approval_rate), \n                        y = approval_rate * 100)) +\n  geom_col(fill = cfa_colors$blue) +\n  coord_flip() +\n  labs(\n    title = \"Approval Rate by ZIP Code (≥10 applications)\",\n    x = \"ZIP Code\",\n    y = \"Approval Rate (%)\"\n  ) +\n  fnc_theme_cfa()\n\n\n\n\n\n\n\n\nNotes:\n\nApproval rates vary from ~34% to ~69% across ZIP codes.\nThis range is large enough to suggest systematic differences, not just noise.\nHigh- and low-performing ZIPs each have reasonable sample sizes, supporting this concern.\n\n\n\nStatistical Test: Is ZIP Predictive of Approval?\nTo formally test whether ZIP code is predictive of approval, I ran a chi-squared test:\n\nzip_test &lt;- exercise_data |&gt;\n  filter(!is.na(approved), !is.na(zip)) |&gt;\n  count(zip, approved) |&gt;\n  pivot_wider(names_from = approved, values_from = n, values_fill = 0) |&gt;\n  column_to_rownames(\"zip\") |&gt;\n  as.matrix() |&gt;\n  chisq.test()\n\nzip_test\n\n\n    Pearson's Chi-squared test\n\ndata:  as.matrix(column_to_rownames(pivot_wider(count(filter(exercise_data,     !is.na(approved), !is.na(zip)), zip, approved), names_from = approved,     values_from = n, values_fill = 0), \"zip\"))\nX-squared = 43.85, df = 27, p-value = 0.02143\n\n\nInterpretation:\n\nThe chi-squared test was statistically significant (p &lt; 0.05).\nWe reject the null hypothesis that approval rates are independent of ZIP code.\nEven without socioeconomic indicators, ZIP appears to meaningfully stratify outcomes.\n\n\n\nPreparation for Modeling\nBefore fitting a model, I created new variables and adjusted a few existing ones to improve interpretability. These changes were grounded in earlier exploratory analysis and CalFresh eligibility rules.\nThe goal was to make model coefficients easier to interpret and ensure alignment with how eligibility and case processing work in practice.\nIncome\n\nexercise_data &lt;- exercise_data |&gt;\n  mutate(income_500 = income / 500)\n\n\nScaled income in $500 units to make coefficients easier to interpret.\nA log-odds change now reflects the effect of each additional ~$500 in monthly income, not each dollar.\n\nApplication Completion Time\n\nexercise_data &lt;- exercise_data |&gt;\n  mutate(\n    completion_time_capped = if_else(completion_time_mins &gt; 180, 180, completion_time_mins),\n    long_app = completion_time_mins &gt; 60\n  )\n\n\nCapped extreme values above 180 minutes to reduce the of outliers.\nFlagged apps that took more than one hour (long_app) to explore whether interruptions or complexity affect outcomes.\n\nInterview Completion (Self-Reported)\n\nexercise_data &lt;- exercise_data |&gt;\n  mutate(interview_completed = case_when(\n    had_interview == TRUE ~ \"Completed\",\n    TRUE ~ \"Not confirmed\"\n  ) |&gt; factor(levels = c(\"Not confirmed\", \"Completed\")))\n\n\nRe-coded had_interview into a 2-category factor:\n\n“Completed” = applicant said they had the interview\n“Not confirmed” = didn’t respond or said no\n\nThis avoids misinterpreting missing data as a definitive “no”"
  },
  {
    "objectID": "analysis.html#comparing-reported-income-to-eligibility-thresholds",
    "href": "analysis.html#comparing-reported-income-to-eligibility-thresholds",
    "title": "Analysis Walkthrough",
    "section": "Comparing Reported Income to Eligibility Thresholds",
    "text": "Comparing Reported Income to Eligibility Thresholds\nTo better understand who should be approved under CalFresh rules, I used the official income eligibility thresholds based on household size.\nThese thresholds reflect the 200% Federal Poverty Level, which applies under California’s Broad-Based Categorical Eligibility policy. If an applicant’s reported income falls below this threshold for their household size, they are likely eligible based on income.\nThis lets us compare:\n\nApproval rates for applicants who appear income-eligible\nDenials among applicants who may meet eligibility requirements\nHow actual decisions align with policy rules\n\n\n\nCode\n# Create eligibility table based on the table here:\n# https://dpss.lacounty.gov/en/food/calfresh/gross-income.html\neligibility_table &lt;- tibble::tibble(\n  household_size = 1:8,\n  max_gross_income = c(2510, 3408, 4304, 5200, 6098, 6994, 7890, 8788)\n)\n\n# Join with application data\nexercise_data &lt;- exercise_data |&gt;\n  left_join(eligibility_table, by = \"household_size\") |&gt;\n  mutate(\n    income_eligible = income &lt;= max_gross_income\n  )\n\n# Approval summary by income eligibility\napproval_summary &lt;- exercise_data |&gt;\n  group_by(income_eligible) |&gt;\n  summarize(\n    n = n(),\n    approval_rate = mean(approved, na.rm = TRUE),\n    approved_over_income = sum(approved & !income_eligible, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  mutate(\n    approval_rate = round(approval_rate * 100, 1)\n  )\n\n# Highlight minimum approval rate\nmin_rate &lt;- min(approval_summary$approval_rate, na.rm = TRUE)\n\napproval_summary |&gt;\n  gt::gt() |&gt;\n  gt::cols_label(\n    income_eligible = \"Income-Eligible?\",\n    n = \"N\",\n    approval_rate = \"Approval Rate (%)\",\n    approved_over_income = \"Approved Despite High Income\"\n  ) |&gt;\n  gt::fmt_number(columns = c(n, approved_over_income), decimals = 0) |&gt;\n  gt::tab_options(\n    table.font.names = \"Source Sans 3\",\n    column_labels.font.weight = \"bold\",\n    column_labels.background.color = \"#ece9f9\",\n    table.border.top.width = gt::px(0),\n    table.border.bottom.width = gt::px(0),\n    heading.title.font.size = 16,\n    data_row.padding = gt::px(4),\n    table.width = gt::pct(100)\n  ) \n\n\n\n\n\n\n\n\nIncome-Eligible?\nN\nApproval Rate (%)\nApproved Despite High Income\n\n\n\n\nFALSE\n43\n9.3\n4\n\n\nTRUE\n1,997\n57.1\n0\n\n\nNA\n6\n50.0\n0\n\n\n\n\n\n\n\nTakeaways:\n\nThe majority of applicants appear income-eligible based on self-reported income and household size.\nA small number of applicants were approved despite being over the income threshold — this could reflect errors, exemptions, or differences in verified income.\nRoughly half of income-eligible applicants were not approved, suggesting process-related barriers (e.g., documents, interviews) play a major role.\n\nThis comparison provides a baseline for interpreting the model results in the next section — especially when we see eligible applicants being denied."
  },
  {
    "objectID": "analysis.html#logistic-regression",
    "href": "analysis.html#logistic-regression",
    "title": "Analysis Walkthrough",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nTo identify factors most strongly associated with CalFresh approval, I fit a logistic regression model. This model estimates the likelihood of approval based on eligibility-related variables and applicant actions observed through the application process.\n\nVariable Selection Rationale\nI included variables based on:\n\nProgram relevance (e.g., income, household size)\nUser experience (e.g., document upload, interview)\nResults from earlier exploratory analysis\n\nThe final model uses:\n\nScaled income: income_500\nHousehold composition: household_size, under18_n, over_59_n\nDocument submission: docs_with_app, docs_after_app\nTime spent applying: completion_time_capped\nHousing stability: stable_housing\nInterview completion: interview_completed (re-coded)\n\n\n\nModel Specification\n\napproval_model &lt;- glm(\n  approved ~ income_500 + household_size + under18_n + over_59_n +\n    docs_with_app + docs_after_app + completion_time_capped +\n    stable_housing + interview_completed,\n  data = exercise_data,\n  family = binomial()\n)\n\nsummary(approval_model)\n\n\nCall:\nglm(formula = approved ~ income_500 + household_size + under18_n + \n    over_59_n + docs_with_app + docs_after_app + completion_time_capped + \n    stable_housing + interview_completed, family = binomial(), \n    data = exercise_data)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                   0.628432   0.131272   4.787 1.69e-06 ***\nincome_500                   -0.412618   0.029816 -13.839  &lt; 2e-16 ***\nhousehold_size               -0.125768   0.088893  -1.415  0.15712    \nunder18_n                     0.300545   0.117048   2.568  0.01024 *  \nover_59_n                     0.121020   0.155961   0.776  0.43777    \ndocs_with_app                 0.116576   0.025326   4.603 4.16e-06 ***\ndocs_after_app                0.075872   0.027076   2.802  0.00507 ** \ncompletion_time_capped       -0.001958   0.002632  -0.744  0.45674    \nstable_housingTRUE           -0.086942   0.112313  -0.774  0.43887    \ninterview_completedCompleted  1.098309   0.118276   9.286  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2800.1  on 2041  degrees of freedom\nResidual deviance: 2373.5  on 2032  degrees of freedom\n  (4 observations deleted due to missingness)\nAIC: 2393.5\n\nNumber of Fisher Scoring iterations: 4\n\n\nInterpretation:\n\nInterview completed had the strongest association with approval.\nHigher income reduced the odds of approval, as expected.\nDocument uploads (both with and after application) were positively associated with approval.\nEach additional child was associated with higher approval odds.\nOther variables (e.g., housing stability, household size, older adults, app time) were not significant once the above were accounted for.\n\n\n\nOdds Ratios and Confidence Intervals\n\nmodel_results &lt;- broom::tidy(approval_model, exponentiate = TRUE, conf.int = TRUE)\n\nmodel_results |&gt;\n  select(term, estimate, conf.low, conf.high, p.value) |&gt;\n  mutate(across(where(is.numeric), round, 2)) |&gt;\n  gt::gt() |&gt;\n  gt::cols_label(\n    term = \"Variable\",\n    estimate = \"Odds Ratio\",\n    conf.low = \"95% CI (Low)\",\n    conf.high = \"95% CI (High)\",\n    p.value = \"P-Value\"\n  ) |&gt;\n  fnc_style_gt_table()\n\n\n\n\n\n\n\nVariable\nOdds Ratio\n95% CI (Low)\n95% CI (High)\nP-Value\n\n\n\n\n(Intercept)\n1.87\n1.45\n2.43\n0.00\n\n\nincome_500\n0.66\n0.62\n0.70\n0.00\n\n\nhousehold_size\n0.88\n0.74\n1.05\n0.16\n\n\nunder18_n\n1.35\n1.07\n1.70\n0.01\n\n\nover_59_n\n1.13\n0.83\n1.53\n0.44\n\n\ndocs_with_app\n1.12\n1.07\n1.18\n0.00\n\n\ndocs_after_app\n1.08\n1.02\n1.14\n0.01\n\n\ncompletion_time_capped\n1.00\n0.99\n1.00\n0.46\n\n\nstable_housingTRUE\n0.92\n0.74\n1.14\n0.44\n\n\ninterview_completedCompleted\n3.00\n2.38\n3.79\n0.00\n\n\n\n\n\n\n\n\nAn odds ratio &gt; 1 means the variable is associated with a higher chance of approval\nAn odds ratio &lt; 1 means a lower chance\n\nInterpretation:\n\nInterview completed: ~3x higher odds of approval\nEach $500 in income: ~34% lower odds\nEach document uploaded with the application: ~12% higher odds\nEach child (under 18): ~35% higher odds\n\nThese results reinforce earlier descriptive findings — but also show that certain variables (like app duration or housing status) have little added explanatory value once core factors are controlled for."
  },
  {
    "objectID": "analysis.html#predicted-probabilities",
    "href": "analysis.html#predicted-probabilities",
    "title": "Analysis Walkthrough",
    "section": "Predicted Probabilities",
    "text": "Predicted Probabilities\nThe logistic regression model produces a predicted probability of approval for each application. These values reflect how likely someone was to be approved, based on their reported information and process steps.\nLooking at predicted probabilities helps identify:\n\nWho was almost certain to be approved or denied\nWho was in a gray zone, where approval was uncertain\nWhere small changes — like completing an interview — might make a difference\n\n\nDistribution of Predicted Probabilities\nAdd predicted probabilities to the data:\n\nmodel_data &lt;- model.frame(approval_model) |&gt;\n  mutate(predicted_prob = predict(approval_model, type = \"response\"))\n\n\nggplot(model_data, aes(x = predicted_prob)) +\n  geom_histogram(fill = cfa_colors$blue, color = \"white\", bins = 30) +\n  labs(\n    title = \"Predicted Probability of CalFresh Approval\",\n    x = \"Predicted Probability\",\n    y = \"Number of Applicants\"\n  ) +\n  fnc_theme_cfa()\n\n\n\n\n\n\n\n\nInterpretation:\n\nMost applicants had predicted probabilities between 0.3 and 0.8, with two peaks:\n\nA major peak centered around 0.65\nA secondary peak around 0.8\n\nThere are fewer applicants with very low (near 0) or very high (near 1) probabilities, which makes sense — no single factor fully determines approval.\n\nThe distribution suggests real variability in approval likelihood — and that many applicants fall into a moderate range of uncertainty, not extremes.\n\n\nExample: Interview Completion\nTo show how much one variable matters, I compared average predicted probabilities by interview status:\n\nmodel_data |&gt;\n  group_by(interview_completed) |&gt;\n  summarize(\n    mean_pred_prob = round(mean(predicted_prob), 2),\n    n = n()\n  ) |&gt;\n  gt::gt() |&gt;\n  gt::cols_label(\n    interview_completed = \"Interview Completed?\",\n    mean_pred_prob = \"Avg. Predicted Probability\",\n    n = \"N\"\n  ) |&gt;\n  gt::fmt_number(columns = n, decimals = 0) |&gt;\n  fnc_style_gt_table()\n\n\n\n\n\n\n\nInterview Completed?\nAvg. Predicted Probability\nN\n\n\n\n\nNot confirmed\n0.49\n1,161\n\n\nCompleted\n0.72\n472\n\n\n\n\n\n\n\nInterpretation:\n\nApplicants who completed the interview had a 72% average predicted chance of approval\nThose who did not (or did not confirm) had just a 50% chance\n\nThis 22-point gap is one of the clearest signals in the model — and points to a place where better support could help.\n\n\nSegmenting Applicants\nTo better understand who might benefit from support, I grouped applicants by predicted approval probability. This helps identify:\n\nWho is most likely to be approved or denied\nWho falls into a gray area, where outcomes are harder to predict\n\nDefine confidence bands:\n\nmodel_data &lt;- model_data |&gt;\n  mutate(prob_band = case_when(\n    predicted_prob &lt; 0.4 ~ \"Low (&lt;40%)\",\n    predicted_prob &gt;= 0.4 & predicted_prob &lt; 0.6 ~ \"Moderate (40–59%)\",\n    predicted_prob &gt;= 0.6 & predicted_prob &lt; 0.8 ~ \"High (60–79%)\",\n    predicted_prob &gt;= 0.8 ~ \"Very High (80%+)\"\n  ) |&gt; factor(levels = c(\"Low (&lt;40%)\", \"Moderate (40–59%)\", \"High (60–79%)\", \"Very High (80%+)\")))\n\nSummary by band:\n\nmodel_data |&gt;\n  group_by(prob_band) |&gt;\n  summarize(\n    n = n(),\n    actual_approval_rate = round(mean(approved, na.rm = TRUE) * 100, 1)\n  ) |&gt;\n  gt::gt() |&gt;\n  gt::cols_label(\n    prob_band = \"Predicted Probability Band\",\n    n = \"N\",\n    actual_approval_rate = \"Observed Approval Rate (%)\"\n  ) |&gt;\n  fnc_style_gt_table()\n\n\n\n\n\n\n\nPredicted Probability Band\nN\nObserved Approval Rate (%)\n\n\n\n\nLow (&lt;40%)\n408\n23.0\n\n\nModerate (40–59%)\n316\n48.4\n\n\nHigh (60–79%)\n654\n67.9\n\n\nVery High (80%+)\n255\n85.9\n\n\n\n\n\n\n\nInterpretation:\n\nVery High (80%+): Most of these applicants were approved — minimal intervention needed.\nHigh (60–79%): Still strong performance, but some denials suggest small process gaps (e.g., missing docs).\nModerate (40–59%): This is the gray zone — almost half are denied. This group could benefit most from added support.\nLow (&lt;40%): Most were denied, but if any were income-eligible, this may indicate missed opportunities.\n\n\n\nGray Zone\nTo learn more about applicants in the 40–59% predicted range, I created a summary of their characteristics.\n\n# Get only the rows used in the model\nused_rows &lt;- as.numeric(rownames(model.frame(approval_model)))\n\n# Add predicted probabilities + other variables used in analysis\nmodel_data &lt;- exercise_data[used_rows, ] |&gt;\n  mutate(\n    predicted_prob = predict(approval_model, type = \"response\")\n  )\n\ngray_zone &lt;- model_data |&gt; \n  filter(predicted_prob &gt;= 0.4, predicted_prob &lt; 0.6)\n\ngray_zone_summary &lt;- gray_zone |&gt; \n  summarize(\n    n = n(),\n    approval_rate = round(mean(approved, na.rm = TRUE) * 100, 1),\n    pct_income_eligible = round(mean(income_eligible, na.rm = TRUE) * 100, 1),\n    pct_docs_with_app = round(mean(docs_with_app &gt; 0) * 100, 1),\n    pct_docs_after_app = round(mean(docs_after_app &gt; 0) * 100, 1),\n    pct_completed_interview = round(mean(interview_completed == \"Completed\") * 100, 1)\n  )\n\ngray_zone_summary |&gt;\n  pivot_longer(everything()) |&gt;\n  gt::gt() |&gt;\n  gt::cols_label(\n    name = \"Metric\",\n    value = \"%\"\n  ) |&gt;\n  gt::fmt_number(columns = value, decimals = 1) |&gt;\n  fnc_style_gt_table()\n\n\n\n\n\n\n\nMetric\n%\n\n\n\n\nn\n316.0\n\n\napproval_rate\n50.6\n\n\npct_income_eligible\n98.4\n\n\npct_docs_with_app\n46.5\n\n\npct_docs_after_app\n24.4\n\n\npct_completed_interview\n31.3\n\n\n\n\n\n\n\nWhat stands out:\n\nNearly half of the gray zone applicants were approved\n99% appear income-eligible, but:\n\nOnly 38% submitted documents with their application\nOnly 22% completed the interview\n\n\nThis group represents a major opportunity: they’re likely eligible, but many didn’t complete the full process. Small nudges or reminders could meaningfully increase approvals."
  },
  {
    "objectID": "analysis.html#example-interview-completion",
    "href": "analysis.html#example-interview-completion",
    "title": "Analysis Walkthrough",
    "section": "Example: Interview Completion",
    "text": "Example: Interview Completion\nTo illustrate the impact of one variable, here’s the average predicted approval probability by interview status:\n\n\nCode\nmodel_data |&gt;\n  group_by(interview_completed) |&gt;\n  summarize(\n    mean_pred_prob = round(mean(predicted_prob), 2),\n    n = n()\n  ) |&gt;\n  gt::gt() |&gt;\n  gt::cols_label(\n    interview_completed = \"Interview Completed?\",\n    mean_pred_prob = \"Avg. Predicted Probability\",\n    n = \"N\"\n  ) |&gt;\n  gt::fmt_number(columns = n, decimals = 0) |&gt;\n  gt::tab_options(\n    table.font.names = \"Source Sans 3\",\n    column_labels.font.weight = \"bold\",\n    column_labels.background.color = \"#ece9f9\",\n    heading.title.font.size = 16,\n    data_row.padding = gt::px(4),\n    table.width = gt::pct(100)\n  )\n\n\n\n\n\n\n\n\nInterview Completed?\nAvg. Predicted Probability\nN\n\n\n\n\nNot confirmed\n0.50\n1,447\n\n\nCompleted\n0.72\n595\n\n\n\n\n\n\n\nInterpretation:\n\nApplicants who completed the interview had a 72% average predicted chance of approval\nThose who did not (or did not confirm) had just a 50% chance\nThis 22-point gap is one of the largest in the model\n\nSupporting applicants through the interview process — with reminders, assistance, or flexibility — may meaningfully increase approval rates for eligible households."
  },
  {
    "objectID": "analysis.html#segmenting-applicants-by-predicted-risk",
    "href": "analysis.html#segmenting-applicants-by-predicted-risk",
    "title": "Analysis Walkthrough",
    "section": "Segmenting Applicants by Predicted Risk",
    "text": "Segmenting Applicants by Predicted Risk\nTo better understand where the system might intervene, I grouped applicants based on their predicted approval probability. This helps identify:\n\nWho is most likely to be approved or denied\nWho falls into a gray area, where outcomes are harder to predict\nWhere process support could make the biggest impact\n\nDefine condidence bands:\n\n\nCode\nmodel_data &lt;- model_data |&gt;\n  mutate(prob_band = case_when(\n    predicted_prob &lt; 0.4 ~ \"Low (&lt;40%)\",\n    predicted_prob &gt;= 0.4 & predicted_prob &lt; 0.6 ~ \"Moderate (40–59%)\",\n    predicted_prob &gt;= 0.6 & predicted_prob &lt; 0.8 ~ \"High (60–79%)\",\n    predicted_prob &gt;= 0.8 ~ \"Very High (80%+)\"\n  ) |&gt; factor(levels = c(\"Low (&lt;40%)\", \"Moderate (40–59%)\", \"High (60–79%)\", \"Very High (80%+)\")))\n\n\nSummary by band:\n\n\nCode\nmodel_data |&gt;\n  group_by(prob_band) |&gt;\n  summarize(\n    n = n(),\n    actual_approval_rate = round(mean(approved, na.rm = TRUE) * 100, 1)\n  ) |&gt;\n  gt::gt() |&gt;\n  gt::cols_label(\n    prob_band = \"Predicted Probability Band\",\n    n = \"N\",\n    actual_approval_rate = \"Observed Approval Rate (%)\"\n  ) |&gt;\n  gt::tab_options(\n  table.font.names = \"Source Sans 3\",\n  column_labels.font.weight = \"bold\",\n  column_labels.background.color = \"#ece9f9\",\n  heading.title.font.size = 16,\n  data_row.padding = gt::px(4),\n  table.width = gt::pct(100)\n  )\n\n\n\n\n\n\n\n\nPredicted Probability Band\nN\nObserved Approval Rate (%)\n\n\n\n\nLow (&lt;40%)\n497\n23.7\n\n\nModerate (40–59%)\n392\n47.4\n\n\nHigh (60–79%)\n823\n67.8\n\n\nVery High (80%+)\n330\n86.1\n\n\n\n\n\n\n\nInterpretation:\n\nVery High (80%+): Most of these applicants were approved — minimal intervention needed.\nHigh (60–79%): Still strong performance, but some denials suggest small process gaps (e.g., missing docs).\nModerate (40–59%): This is the gray zone — almost half are denied. This group could benefit most from added support.\nLow (&lt;40%): Most were denied, but if any were income-eligible, this may indicate missed opportunities.\n\nThis segmentation provides a framework for identifying who is at risk and how interventions might be targeted — not just based on who was denied, but based on who was predicted to succeed."
  },
  {
    "objectID": "analysis.html#profile-of-the-moderate-band-4059",
    "href": "analysis.html#profile-of-the-moderate-band-4059",
    "title": "Analysis Walkthrough",
    "section": "Profile of the Moderate Band (40–59%)",
    "text": "Profile of the Moderate Band (40–59%)\nApplicants with predicted approval probabilities between 40% and 59% are in a decision gray zone. These are users who:\n\nHad mixed signals in their application\nMay be eligible, but didn’t complete all steps\nCould potentially be approved with light-touch support\n\n\n\nCode\n# Get only the rows used in the model\nused_rows &lt;- as.numeric(rownames(model.frame(approval_model)))\n\n# Add predicted probabilities + other variables used in analysis\nmodel_data &lt;- exercise_data[used_rows, ] |&gt;\n  mutate(\n    predicted_prob = predict(approval_model, type = \"response\")\n  )\n\ngray_zone &lt;- model_data |&gt; \n  filter(predicted_prob &gt;= 0.4, predicted_prob &lt; 0.6)\n\ngray_zone_summary &lt;- gray_zone |&gt; \n  summarize(\n    n = n(),\n    approval_rate = round(mean(approved, na.rm = TRUE) * 100, 1),\n    pct_income_eligible = round(mean(income_eligible, na.rm = TRUE) * 100, 1),\n    pct_docs_with_app = round(mean(docs_with_app &gt; 0) * 100, 1),\n    pct_docs_after_app = round(mean(docs_after_app &gt; 0) * 100, 1),\n    pct_completed_interview = round(mean(interview_completed == \"Completed\") * 100, 1)\n  )\n\ngray_zone_summary |&gt;\n  pivot_longer(everything()) |&gt;\n  gt::gt() |&gt;\n  gt::cols_label(\n    name = \"Metric\",\n    value = \"%\"\n  ) |&gt;\n  gt::fmt_number(columns = value, decimals = 1) |&gt;\n  gt::tab_options(\n  table.font.names = \"Source Sans 3\",\n  column_labels.font.weight = \"bold\",\n  column_labels.background.color = \"#ece9f9\",\n  heading.title.font.size = 16,\n  data_row.padding = gt::px(4),\n  table.width = gt::pct(100)\n  )\n\n\n\n\n\n\n\n\nMetric\n%\n\n\n\n\nn\n392.0\n\n\napproval_rate\n47.4\n\n\npct_income_eligible\n99.7\n\n\npct_docs_with_app\n38.0\n\n\npct_docs_after_app\n25.3\n\n\npct_completed_interview\n22.4\n\n\n\n\n\n\n\nThese are likely eligible applicants who didn’t complete key process steps.\nThey’re not clearly ineligible — they’re stuck in the middle of the process. This group represents a major opportunity for low-touch interventions like:\n\nTimely reminders\nText nudges\nInterview scheduling help\nGuided document uploads\n\nMore support could improve outcomes for hundreds of applicants."
  },
  {
    "objectID": "analysis.html#income-eligibility",
    "href": "analysis.html#income-eligibility",
    "title": "Analysis Walkthrough",
    "section": "Income Eligibility",
    "text": "Income Eligibility\nTo better understand who should be approved under CalFresh rules, I used the official income eligibility thresholds based on household size.\nThese limits reflect the 200% Federal Poverty Level under California’s Broad-Based Categorical Eligibility (BBCE) policy.\nThis allows us to distinguish:\n\nApplicants who likely met income-based eligibility\nApplicants who may have been denied despite being income-eligible\nThe extent to which approval decisions align with income thresholds\n\n\n# Create eligibility table based on the table here:\n# https://dpss.lacounty.gov/en/food/calfresh/gross-income.html\neligibility_table &lt;- tibble::tibble(\n  household_size = 1:8,\n  max_gross_income = c(2510, 3408, 4304, 5200, 6098, 6994, 7890, 8788)\n)\n\n# Join with application data\nexercise_data &lt;- exercise_data |&gt;\n  left_join(eligibility_table, by = \"household_size\") |&gt;\n  mutate(\n    income_eligible = income &lt;= max_gross_income\n  )\n\n# Approval summary by income eligibility\napproval_summary &lt;- exercise_data |&gt;\n  group_by(income_eligible) |&gt;\n  summarize(\n    n = n(),\n    approval_rate = mean(approved, na.rm = TRUE),\n    approved_over_income = sum(approved & !income_eligible, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  mutate(\n    approval_rate = round(approval_rate * 100, 1)\n  )\n\n# Highlight minimum approval rate\nmin_rate &lt;- min(approval_summary$approval_rate, na.rm = TRUE)\n\napproval_summary |&gt;\n  gt::gt() |&gt;\n  gt::cols_label(\n    income_eligible = \"Income-Eligible?\",\n    n = \"N\",\n    approval_rate = \"Approval Rate (%)\",\n    approved_over_income = \"Approved Despite High Income\"\n  ) |&gt;\n  gt::fmt_number(columns = c(n, approved_over_income), decimals = 0) |&gt;\n  fnc_style_gt_table()\n\n\n\n\n\n\n\nIncome-Eligible?\nN\nApproval Rate (%)\nApproved Despite High Income\n\n\n\n\nFALSE\n43\n9.3\n4\n\n\nTRUE\n1,997\n57.1\n0\n\n\nNA\n6\n50.0\n0\n\n\n\n\n\n\n\nTakeaways:\n\nMost applicants appear income-eligible.\nA small number were approved despite exceeding income thresholds — potentially due to exceptions, data entry errors, or income verification.\nNearly half of income-eligible applicants were not approved, pointing to process barriers like missed interviews or incomplete documentation.\n\nThis flag helps contextualize approval decisions in the model, especially when eligible applicants are denied."
  },
  {
    "objectID": "analysis.html#conclusion",
    "href": "analysis.html#conclusion",
    "title": "Analysis Walkthrough",
    "section": "Conclusion",
    "text": "Conclusion\nThis analysis examined patterns in CalFresh (SNAP) application outcomes among GetCalFresh.org users in San Diego County. Several process-related factors were strongly associated with whether an applicant was approved.\n\nKey Findings:\n\nInterview completion was the most predictive factor: Applicants who reported completing the interview were nearly three times more likely to be approved.\nDocument uploads mattered: Uploading verification documents — especially with the initial application — was associated with higher approval rates.\nHigher income reduced the odds of approval: This aligns with program rules. Each additional $500 in income lowered approval odds by about one-third.\nMany income-eligible applicants were not approved: Nearly half of income-eligible applicants were denied, suggesting process-related barriers (e.g., missing interviews or documents) play a major role.\nZIP code predicted approval differences: Approval rates varied significantly by ZIP, pointing to geographic disparities in access or processing.\nA large group fell into a “gray zone”: Applicants with a predicted approval probability between 40–59% were often income-eligible but lacked key follow-through steps. This is a high-impact group for outreach or nudges."
  },
  {
    "objectID": "analysis.html#next-steps-areas-for-deeper-analysis",
    "href": "analysis.html#next-steps-areas-for-deeper-analysis",
    "title": "Analysis Walkthrough",
    "section": "Next Steps: Areas for Deeper Analysis",
    "text": "Next Steps: Areas for Deeper Analysis\nThis section outlines follow-up analyses and design considerations to expand on the current findings and inform future improvements to the CalFresh application process.\n\nGeographic and Neighborhood Variation\n\nLink ZIP codes to American Community Survey (ACS) indicators:\n\nPoverty rate\nHousing burden\nBroadband access\nLanguages spoken at home\n\nMap approval rates by neighborhood to identify areas with potential access barriers\nAssess whether geographic disparities persist after controlling for applicant characteristics\n\n\n\nQualitative Research\n\nInterview applicants to:\n\nUnderstand perceived barriers in the process\nIdentify confusing or unclear steps\nExplore unmet needs for documentation or interview follow-up\n\nReview SMS or helpdesk interactions for common pain points\n\n\n\nTiming and Process Flow\n\nAnalyze time between:\n\nApplication start and finish\nApplication and document upload\nApplication and interview completion\n\nIdentify drop-off points or common delays in the flow\nExplore whether earlier intervention (e.g., reminders) affects outcomes\n\n\n\nAlternative Modeling Approaches\n\nTest interpretable models (e.g., decision trees) to identify interaction effects.\nUse cross-validation or bootstrap confidence intervals to strengthen robustness.\nExplore how assumptions about missing interviews affect results.\n\n\n\nApplicant Segmentation\n\nSegment applicants based on predicted probability and income eligibility\nIdentify profiles for targeted support:\n\nEligible but denied\nHigh predicted approval but not approved\n\n\n\n\nSystem and Policy Implications\n\nShare ZIP-level insights with county caseworkers and program administrators\nEvaluate platform changes (e.g., nudges, scheduling tools, help prompts) for impact on completion and approval\nExplore partnerships for assisted application support in low-approval ZIPs\n\n\n# Save data\nsaveRDS(approval_model, file = \"models/approval_model.rds\")"
  },
  {
    "objectID": "key_findings.html#based-on-your-results-where-would-you-look-next-in-terms-of-identifying-potential-improvements",
    "href": "key_findings.html#based-on-your-results-where-would-you-look-next-in-terms-of-identifying-potential-improvements",
    "title": "Key Findings",
    "section": "2. Based on your results, where would you look next in terms of identifying potential improvements?",
    "text": "2. Based on your results, where would you look next in terms of identifying potential improvements?\nThe analysis highlights several areas where small changes could lead to better outcomes for eligible applicants. The interview appears to be a major point of drop-off—many applicants never confirm completing it, even when their income suggests they may qualify. Providing clearer instructions, reminders, or interview scheduling support could help applicants complete this critical step.\nDocument uploads also matter. Applicants who submit documents with their initial application are more likely to be approved. This points to a design opportunity: encouraging early uploads, clarifying what’s needed, or even pre-filling document types based on income or household size might boost follow-through.\n\nKey Findings for Stakeholders\nBased on the patterns found in the data, there are clear opportunities to improve access and outcomes:\n\nFocus on the interview: Many eligible applicants never confirm completing it. Better reminders or easier scheduling could help.\nEncourage early documentation: Applicants who submit documents up front are more likely to be approved. Prompting users to upload at the start — with clearer instructions — may help more get across the finish line.\nLook into ZIP code disparities: Some neighborhoods had lower approval rates, even after accounting for income. Exploring local challenges — like broadband access or language support — could explain these gaps.\nLearn from the “gray zone”: Many applicants who were likely eligible still got denied. Interviews or user testing could reveal what stopped them from finishing the process.\nTarget support where it matters: Use predicted approval probabilities to identify groups most at risk of falling through the cracks — and intervene with simple nudges or guidance.\n\n\nNext steps could include:\n\nAnalyzing ZIP code–level variation using demographic data (e.g., broadband access, language access, poverty rates) to identify geographic barriers.\nConducting qualitative interviews with users who appear income-eligible but were not approved to understand confusion or friction points in more detail.\n\nThese additional steps would help identify whether barriers are driven by misunderstanding, access gaps, or specific policy implementation practices at the county level."
  },
  {
    "objectID": "key_findings.html#based-on-your-results-where-would-you-look-next-to-improve-the-application",
    "href": "key_findings.html#based-on-your-results-where-would-you-look-next-to-improve-the-application",
    "title": "Key Findings",
    "section": "2. Based on your results, where would you look next to improve the application?",
    "text": "2. Based on your results, where would you look next to improve the application?\nThe biggest opportunities for improvement appear after the application is submitted. Applicants who didn’t confirm an interview or didn’t submit documents were much less likely to be approved — even when income-eligible. Many of these users fall into a “gray zone” with a 40–59% predicted chance of approval.\n\nSummary:\n\nHelp applicants complete interviews with reminders, pre-scheduling options, or simplified confirmation workflows.\nEncourage early document uploads by guiding users to upload verification documents during the application flow, especially when they’re likely to qualify.\nSegment support for those in the gray zone (e.g., predicted approval between 40–59%) to increase throughput without expanding eligibility.\nExplore geographic disparities in approval outcomes across ZIP codes, potentially linked to caseloads or infrastructure (e.g., broadband access).\n\nThese targeted improvements could reduce drop-off among eligible users and make the approval process more efficient and equitable."
  },
  {
    "objectID": "key_findings.html#factors-associated-with-approval",
    "href": "key_findings.html#factors-associated-with-approval",
    "title": "Key Findings",
    "section": "1. Factors Associated With Approval",
    "text": "1. Factors Associated With Approval\nTo identify which factors were most strongly associated with CalFresh approval, a logistic regression model was used. The outcome variable was whether an application was approved. Predictors included self-reported income, household composition, housing stability, interview completion (self-reported), and document submission behavior (before and after application). Variables were selected based on program relevance, user behavior, and exploratory analysis.\nAll numeric variables were checked for correlation and scaled for interpretability (e.g., income was divided by $500). Missing data were minimal except for had_interview, which was recoded as a categorical variable with an “unknown” level to avoid excluding many applicants. The model achieved a McFadden R² of 0.15 and an AUC of 0.76 — indicating good fit and predictive performance using only application-facing data.\nKey Results and Interpretations\nThe table below summarizes the model results, with both statistical detail and a plain-language interpretation for each variable. This format supports both researchers and stakeholders.\n\n\n\n\n\n\n\n\nVariable\nOdds Ratio\n95% CI (Low)\n95% CI (High)\nP-Value\nInterpretation\n\n\n\n\nBaseline (reference)\n2.02\n1.51\n2.71\n0.00\nBaseline odds (intercept)\n\n\nIncome (per $500)\n0.67\n0.62\n0.71\n0.00\nHigher income was linked to lower approval\n\n\nHousehold Size\n0.83\n0.68\n1.01\n0.07\nLarger households were not significantly different\n\n\nChildren in Household\n1.46\n1.13\n1.89\n0.00\nEach child increased odds of approval\n\n\nOlder Adults in Household\n1.20\n0.85\n1.70\n0.29\nNo significant effect\n\n\nDocs Submitted With Application\n1.13\n1.07\n1.19\n0.00\nEach document increased approval odds by ~12%\n\n\nDocs Submitted After Application\n1.07\n1.01\n1.14\n0.02\nEach document had a small positive effect\n\n\nApplication Time (minutes)\n1.00\n0.99\n1.00\n0.20\nLonger applications showed no strong association\n\n\nStable Housing\n0.90\n0.70\n1.15\n0.38\nNo clear difference after accounting for other factors\n\n\nInterview Completed\n2.99\n2.31\n3.89\n0.00\nStrongest predictor of approval\n\n\n\n\n\n\n\n\nSummary:\n\nInterview completion was the strongest predictor of approval. Applicants who confirmed completing the interview had a predicted approval rate of ~72%, compared to 50% for others.\nDocument submission with the application improved outcomes. Each document uploaded increased approval odds.\nHigher income reduced approval odds, consistent with eligibility thresholds.\nHaving children on the application increased approval likelihood, while housing stability and application duration had no significant impact after adjusting for other variables."
  },
  {
    "objectID": "key_findings.html#potential-improvements",
    "href": "key_findings.html#potential-improvements",
    "title": "Key Findings",
    "section": "2. Potential Improvements",
    "text": "2. Potential Improvements\nThe biggest opportunities for improvement appear after the application is submitted. Applicants who didn’t confirm an interview or didn’t submit documents were much less likely to be approved — even when income-eligible.\n\nSummary:\n\nHelp applicants complete interviews with reminders, pre-scheduling options, or simplified confirmation workflows.\nEncourage early document uploads by guiding users to upload verification documents during the application flow, especially when they’re likely to qualify.\nExplore geographic disparities in approval outcomes across ZIP codes, potentially linked to caseloads or infrastructure (e.g., broadband access).\n\nThese targeted improvements could reduce drop-off among eligible users and make the approval process more efficient and equitable."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n\n\n\n\n\n\nExample Callout\n\n\n\n\n\nThis section expands on scroll or click."
  },
  {
    "objectID": "analysis.html#overview",
    "href": "analysis.html#overview",
    "title": "Analysis Walkthrough",
    "section": "",
    "text": "This analysis explores which factors are associated with whether a CalFresh (SNAP) application is approved or denied. The data come from 2,046 applications submitted through GetCalFresh.org in San Diego County.\n\nOur goal is to understand:\n\nWhat factors are associated with whether an applicant is approved or denied\nWhere in the process users may drop off, face barriers, or get delayed\nHow the application experience could be improved for users\n\n\nThis is not a causal analysis. Instead, it aims to show practical insights about patterns in approval outcomes, using variables tied to both applicant eligibility and their interactions with the process."
  }
]