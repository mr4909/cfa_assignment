[
  {
    "objectID": "key_findings.html#where-would-you-look-next-to-improve-the-application-process",
    "href": "key_findings.html#where-would-you-look-next-to-improve-the-application-process",
    "title": "Key Findings",
    "section": "Where would you look next to improve the application process?",
    "text": "Where would you look next to improve the application process?"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "For questions or additional information, feel free to contact:\nMari Roberts\nProject Author\nEmail: marialexandriaroberts@gmail.com\nGitHub: @mr4909"
  },
  {
    "objectID": "contact.html#team",
    "href": "contact.html#team",
    "title": "Contact",
    "section": "",
    "text": "For questions or additional information, feel free to contact:\nMari Roberts\nProject Author\nEmail: marialexandriaroberts@gmail.com\nGitHub: @mr4909"
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This exploratory analysis examines factors associated with CalFresh application approval among San Diego County users of GetCalFresh.org. The goal is to:\n\nUnderstand the barriers applicants may face\nIdentify features most associated with success\nHighlight opportunities for improving user outcomes\n\nResearch Questions:\n\nWhat factors are most strongly associated with CalFresh approval?\nWhere might the process be improved to reduce unnecessary drop-off or denials?"
  },
  {
    "objectID": "analysis.html#reviewing-the-calfresh-application",
    "href": "analysis.html#reviewing-the-calfresh-application",
    "title": "Analysis",
    "section": "",
    "text": "Before conducting any data analysis, I walked through the GetCalFresh.org application process myself to better understand the applicant experience. This helped clarify what each variable in the dataset represents and how users encounter them in practice.\n\n\n\nCalFresh Survey Image\n\n\n\n\n\nMultilingual Support is available from the start (English, Spanish, Chinese, Vietnamese), with more preferred language options at the end of the process.\nThe application is staged, moving through: household info → income → expenses → contact details → confirmation.\nApplicants receive real-time feedback on whether they may qualify, including notifications about potential expedited processing timelines.\nSubmission does not require everything at once. Document uploads and interviews can happen after submission, making these potential barriers to completion, not eligibility.\n\n\n\n\nToward the end of the process, applicants are asked to:\n\nConfirm contact information (phone, email, language preferences)\nSelect mailing address options — including a note that a mailing address is required for benefit delivery but can be substituted with PO boxes or addresses of trusted third parties\nProvide interview availability and request accommodations (e.g., interpreters, help with disabilities)\nOpt into reminders via SMS and email, which are used to prompt follow-up actions\n\nPeople can drop off at this stage — just before final submission — for reasons unrelated to eligibility, such as technical issues, unclear instructions, privacy concerns, immigration status concerns, or timing conflicts with the required interview.\n\n\n\nThe user experience walk through shaped my interpretation of key fields:\n\nhad_interview: Based on a follow-up text message response, not a verified system event. Missing values do not confirm no interview — just that it wasn’t captured via GetCalFresh.\ndocs_with_app vs. docs_after_app: Reflect when documentation was uploaded through the platform. Counties may have received documents by other means (mail, fax, in person).\ncompletion_time_mins: Captures elapsed time from start to finish, but may reflect interruptions or household complexity — not necessarily user effort or intent."
  },
  {
    "objectID": "analysis.html#about-the-data",
    "href": "analysis.html#about-the-data",
    "title": "Analysis",
    "section": "About the Data",
    "text": "About the Data\nThis dataset includes ~2,000 CalFresh applications submitted through GetCalFresh.org in San Diego County. Each row represents an individual applicant and includes:\n\nDemographic characteristics (household size, presence of children or older adults)\nApplication details (income, completion time, housing stability)\nInteraction with the process (had an interview, uploaded documents)\nOutcome: whether the application was approved (TRUE/FALSE)\n\nNotes:\n\nInterview completion is based on self-reported responses via SMS.\nDocument submission is based only on what was uploaded through GetCalFresh, not via other county channels like mail or in-person."
  },
  {
    "objectID": "analysis.html#research-questions",
    "href": "analysis.html#research-questions",
    "title": "Analysis",
    "section": "Research Questions",
    "text": "Research Questions\nThis analysis is designed to answer:\n\nWhat characteristics are most strongly associated with CalFresh approval?\nWhat might be done to improve application success rates?"
  },
  {
    "objectID": "analysis.html#data-codebook",
    "href": "analysis.html#data-codebook",
    "title": "Analysis",
    "section": "Data Codebook",
    "text": "Data Codebook\nTo ground the analysis in a shared understanding of the data, I generated a structured codebook using a custom function from my databookR package. The codebook:\n\nLists all variables included in the dataset\nProvides plain-language descriptions for each field\nSummarizes data type, number of unique values, missingness, and key statistics\n\nThis serves as both a reference and a check on data quality prior to modeling.\n\n\nCode\n# Add descriptions to variables\nvar_desc &lt;- list(\n  app_id               = \"Unique identifier for each application\",\n  completion_time_mins = \"Time taken to complete the application, in minutes\",\n  household_size       = \"Number of people applying for CalFresh in the household\",\n  income               = \"Total household income in the last 30 days (randomized slightly for privacy)\",\n  docs_with_app        = \"Count of verification documents uploaded with the initial application\",\n  docs_after_app       = \"Count of verification documents uploaded after application (via Later Docs)\",\n  under18_n            = \"Number of children age 17 or younger included in the application\",\n  over_59_n            = \"Number of adults age 60 or older included in the application\",\n  stable_housing       = \"TRUE if applicant rents or owns the place they sleep; FALSE otherwise\",\n  had_interview        = \"TRUE if applicant reported completing the required interview; may be missing\",\n  zip                  = \"ZIP code where the applicant lives or stays\",\n  approved             = \"TRUE if the application was approved for CalFresh by the county\"\n)\n\n# Factor variables\nexercise_data &lt;- exercise_data |&gt; \n  mutate(zip = factor(zip))\n         \n\n# Use custom R package built by Mari Roberts\ndatabookR::databook(exercise_data, var_descriptions = var_desc)\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nVariable Description\nVariable Type\nNumber of Unique Values\nPercentage Missing\nStatistics\n\n\n\n\napp_id\nUnique identifier for each application\nnumeric\n2046\n0.0%\nMin: 1.0\nAvg: 38866.9\nMedian: 38066.5\nMax: 110550.0\nSD: 25305.4\n\n\ncompletion_time_mins\nTime taken to complete the application, in minutes\nnumeric\n2046\n0.0%\nMin: 2.3\nAvg: 21.4\nMedian: 10.4\nMax: 8551.8\nSD: 195.7\n\n\nhousehold_size\nNumber of people applying for CalFresh in the household\nnumeric\n10\n0.2%\nMin: 1.0\nAvg: 1.8\nMedian: 1.0\nMax: 12.0\nSD: 1.3\n\n\nincome\nTotal household income in the last 30 days (randomized slightly for privacy)\nnumeric\n888\n0.0%\nMin: 0.0\nAvg: 936.0\nMedian: 270.0\nMax: 9779.0\nSD: 1228.9\n\n\ndocs_with_app\nCount of verification documents uploaded with the initial application\nnumeric\n19\n0.0%\nMin: 0.0\nAvg: 1.3\nMedian: 0.0\nMax: 25.0\nSD: 2.2\n\n\ndocs_after_app\nCount of verification documents uploaded after application (via Later Docs)\nnumeric\n20\n0.0%\nMin: 0.0\nAvg: 0.8\nMedian: 0.0\nMax: 29.0\nSD: 2.1\n\n\nunder18_n\nNumber of children age 17 or younger included in the application\nnumeric\n7\n0.2%\nMin: 0.0\nAvg: 0.5\nMedian: 0.0\nMax: 6.0\nSD: 1.0\n\n\nover_59_n\nNumber of adults age 60 or older included in the application\nnumeric\n3\n0.2%\nMin: 0.0\nAvg: 0.1\nMedian: 0.0\nMax: 2.0\nSD: 0.3\n\n\nstable_housing\nTRUE if applicant rents or owns the place they sleep; FALSE otherwise\nlogical\n2\n0.0%\nTRUE: 1186 (58.0%)\nFALSE: 860 (42.0%)\n\n\nhad_interview\nTRUE if applicant reported completing the required interview; may be missing\nlogical\n2\n49.7%\nTRUE: 595 (57.8%)\nFALSE: 434 (42.2%)\n\n\nzip\nZIP code where the applicant lives or stays\nfactor\n28\n0.0%\nTop 5 Categories:\n92105 = 162 (7.9%)\n92114 = 157 (7.7%)\n92113 = 155 (7.6%)\n92115 = 133 (6.5%)\n92154 = 128 (6.3%)\n\n\napproved\nTRUE if the application was approved for CalFresh by the county\nlogical\n2\n0.0%\nTRUE: 1148 (56.1%)\nFALSE: 898 (43.9%)\n\n\n\n\n\n\n\nThis codebook confirms:\n\nhad_interview has substantial missingness, consistent with the platform limitations noted in the exercise.\ncompletion_time_mins, docs_with_app, and docs_after_app have long-tailed distributions, as expected from process behavior."
  },
  {
    "objectID": "analysis.html#exploratory-data-analysis",
    "href": "analysis.html#exploratory-data-analysis",
    "title": "Analysis",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nBefore modeling, I conducted an exploratory analysis to:\n\nUnderstand distributions and outliers\nIdentify missing values and potential data quality issues\nAssess early relationships with the outcome (approved)\nCheck for multicollinearity and redundancy among predictors\nPrepare variables for modeling and interpretation\n\n\nCodebook\nTo ground the analysis in a shared understanding of the data, I generated a structured codebook using a custom function from my databookR package. The codebook:\n\nLists all variables in the dataset\nProvides plain-language descriptions for each field\nSummarizes data type, missingness, and key statistics\n\n\n\nCode\n# Add descriptions to variables\nvar_desc &lt;- list(\n  app_id               = \"Unique identifier for each application\",\n  completion_time_mins = \"Time taken to complete the application, in minutes\",\n  household_size       = \"Number of people applying for CalFresh in the household\",\n  income               = \"Total household income in the last 30 days (randomized slightly for privacy)\",\n  docs_with_app        = \"Count of verification documents uploaded with the initial application\",\n  docs_after_app       = \"Count of verification documents uploaded after application (via Later Docs)\",\n  under18_n            = \"Number of children age 17 or younger included in the application\",\n  over_59_n            = \"Number of adults age 60 or older included in the application\",\n  stable_housing       = \"TRUE if applicant rents or owns the place they sleep; FALSE otherwise\",\n  had_interview        = \"TRUE if applicant reported completing the required interview; may be missing\",\n  zip                  = \"ZIP code where the applicant lives or stays\",\n  approved             = \"TRUE if the application was approved for CalFresh by the county\"\n)\n\n# Generate codebook\ndatabookR::databook(exercise_data, var_descriptions = var_desc)\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nVariable Description\nVariable Type\nNumber of Unique Values\nPercentage Missing\nStatistics\n\n\n\n\napp_id\nUnique identifier for each application\nnumeric\n2046\n0.0%\nMin: 1.0\nAvg: 38866.9\nMedian: 38066.5\nMax: 110550.0\nSD: 25305.4\n\n\ncompletion_time_mins\nTime taken to complete the application, in minutes\nnumeric\n2046\n0.0%\nMin: 2.3\nAvg: 21.4\nMedian: 10.4\nMax: 8551.8\nSD: 195.7\n\n\nhousehold_size\nNumber of people applying for CalFresh in the household\nnumeric\n10\n0.2%\nMin: 1.0\nAvg: 1.8\nMedian: 1.0\nMax: 12.0\nSD: 1.3\n\n\nincome\nTotal household income in the last 30 days (randomized slightly for privacy)\nnumeric\n888\n0.0%\nMin: 0.0\nAvg: 936.0\nMedian: 270.0\nMax: 9779.0\nSD: 1228.9\n\n\ndocs_with_app\nCount of verification documents uploaded with the initial application\nnumeric\n19\n0.0%\nMin: 0.0\nAvg: 1.3\nMedian: 0.0\nMax: 25.0\nSD: 2.2\n\n\ndocs_after_app\nCount of verification documents uploaded after application (via Later Docs)\nnumeric\n20\n0.0%\nMin: 0.0\nAvg: 0.8\nMedian: 0.0\nMax: 29.0\nSD: 2.1\n\n\nunder18_n\nNumber of children age 17 or younger included in the application\nnumeric\n7\n0.2%\nMin: 0.0\nAvg: 0.5\nMedian: 0.0\nMax: 6.0\nSD: 1.0\n\n\nover_59_n\nNumber of adults age 60 or older included in the application\nnumeric\n3\n0.2%\nMin: 0.0\nAvg: 0.1\nMedian: 0.0\nMax: 2.0\nSD: 0.3\n\n\nstable_housing\nTRUE if applicant rents or owns the place they sleep; FALSE otherwise\nlogical\n2\n0.0%\nTRUE: 1186 (58.0%)\nFALSE: 860 (42.0%)\n\n\nhad_interview\nTRUE if applicant reported completing the required interview; may be missing\nlogical\n2\n49.7%\nTRUE: 595 (57.8%)\nFALSE: 434 (42.2%)\n\n\nzip\nZIP code where the applicant lives or stays\nfactor\n28\n0.0%\nTop 5 Categories:\n92105 = 162 (7.9%)\n92114 = 157 (7.7%)\n92113 = 155 (7.6%)\n92115 = 133 (6.5%)\n92154 = 128 (6.3%)\n\n\napproved\nTRUE if the application was approved for CalFresh by the county\nlogical\n2\n0.0%\nTRUE: 1148 (56.1%)\nFALSE: 898 (43.9%)\n\n\nhousehold_size_bin\nDescription needed.\nfactor\n5\n0.2%\nAll Categories:\n(0,1] = 1223 (59.9%)\n(1,2] = 334 (16.4%)\n(3,5] = 228 (11.2%)\n(2,3] = 227 (11.1%)\n(5,10] = 29 (1.4%)\n\n\ndoc_group\nDescription needed.\nfactor\n4\n0.0%\nAll Categories:\nWith App Only = 797 (39.0%)\nNo Docs = 788 (38.5%)\nAfter App Only = 248 (12.1%)\nWith + After = 213 (10.4%)\n\n\n\n\n\n\n\nNotes:\n\nhad_interview has ~50% missingness, consistent with its self-reported source\nDocument counts (docs_with_app, docs_after_app) are zero-inflated and right-skewed\nOnly 4 missing values in demographic fields like household_size, under18_n, and over_59_n.\n\n\n\nMissingness\n\n\nCode\nvis_miss(exercise_data)\n\n\n\n\n\n\n\n\n\nOnly had_interview contains meaningful missingness. All other fields are effectively complete.\n\n\nDistribution of Key Variables\nI reviewed numeric variables to assess skew, outliers, and plausible ranges.\n\n\nCode\n# Custom binwidths for clarity\nbinwidths &lt;- list(\n  income = 250,\n  completion_time_mins = 40,\n  docs_with_app = 1,\n  docs_after_app = 1,\n  household_size = 1,\n  under18_n = 1,\n  over_59_n = 1\n)\n\n# Plotting function\n# Updated plot_var with optional filter for extreme values\nplot_var &lt;- function(var, title = NULL, max_x = NULL) {\n  data &lt;- exercise_data\n  if (!is.null(max_x)) {\n    data &lt;- data |&gt; filter(.data[[var]] &lt;= max_x)\n  }\n\n  ggplot(data, aes(.data[[var]])) +\n    geom_histogram(\n      binwidth = binwidths[[var]],\n      fill = cfa_colors$blue,\n      color = \"white\",\n      na.rm = TRUE\n    ) +\n    labs(\n      title = title %||% var,\n      x = var,\n      y = \"Count\"\n    ) +\n    theme_minimal(base_family = \"sourcesans\", base_size = 14) +\n    theme(\n      plot.title = element_text(size = 16, face = \"bold\", margin = margin(b = 10)),\n      axis.title = element_text(size = 13),\n      axis.text = element_text(size = 12)\n    )\n}\n\n\n# Generate all plots\nwrap_plots(\n  plot_var(\"income\", \"Monthly Income\"),\n  plot_var(\"completion_time_mins\", \"App Completion Time (Minutes)\", max_x = 120),\n  plot_var(\"docs_with_app\", \"Docs Uploaded With App\"),\n  plot_var(\"docs_after_app\", \"Docs Uploaded After App\"),\n  plot_var(\"household_size\", \"Household Size\"),\n  plot_var(\"under18_n\", \"Children in Household\"),\n  plot_var(\"over_59_n\", \"Older Adults in Household\"),\n  ncol = 2\n)\n\n\n\n\n\n\n\n\n\nNotes:\n\nIncome is right-skewed. Most applicants report monthly income between $0–$500, consistent with SNAP targeting.\nCompletion time clusters under 20 minutes. Outliers over 2 hours likely reflect interruptions.\nDocument fields show many zeros — many applicants do not submit documents online.\nHousehold size is small. Median = 1. Most applicants live alone or with one dependent.\nChild and older adult counts are near-zero for most, but tails exist.\n\n\n\nCorrelation and Redundancy Check\nBefore building a model, I assessed relationships between predictors to check for multicollinearity.\nMulticollinearity can:\n\nInflate coefficient variance\nObscure which features are truly associated with approval\nUndermine interpretability — which is a important in this context\n\nI used two methods:\n\nPairwise correlations for numeric variables\nVariance Inflation Factor (VIF) in a preliminary logistic regression\n\n\n\nCode\n# Subset numeric predictors\nnum_vars &lt;- exercise_data |&gt;\n  select(income, household_size, under18_n, over_59_n, \n         docs_with_app, docs_after_app, completion_time_mins)\n\n# Correlation matrix\ncor_matrix &lt;- cor(num_vars, use = \"complete.obs\")\n\n# Visualize correlation matrix\ncorrplot(cor_matrix, method = \"circle\", type = \"upper\", \n         tl.cex = 0.8, tl.col = \"black\")\n\n\n\n\n\n\n\n\n\nNotes:\n\nunder18_n and household_size are moderately correlated, which is expected.\nOther variable pairs show low correlation, suggesting minimal redundancy.\n\n\n\nCode\n# Quick VIF check with basic logistic model\nvif_model &lt;- glm(\n  approved ~ income + household_size + under18_n + over_59_n +\n    docs_with_app + docs_after_app + completion_time_mins + \n    stable_housing + had_interview,\n  data = exercise_data,\n  family = binomial()\n)\n\ncar::vif(vif_model)\n\n\n              income       household_size            under18_n \n            1.570242             4.949500             4.810768 \n           over_59_n        docs_with_app       docs_after_app \n            1.082801             1.071075             1.094315 \ncompletion_time_mins       stable_housing        had_interview \n            1.012481             1.241863             1.105751 \n\n\n\nhousehold_size (4.95) and under18_n (4.81) show moderate multicollinearity — expected due to their conceptual overlap.\nAll other variables have VIFs below 2.\n\nBoth variables will likely be retained. While correlated, they reflect different eligibility factors: household size affects income limits, while the presence of children may affect processing or priority.\n\n\nApproval Rates by Key Variables\nTo identify process points that may shape outcomes, I calculated approval rates across key variables.\nThis helped guide feature selection and surfaced potential intervention points early.\n\n\nCode\n# Function to summarize approval rates across any categorical variable\nfnc_approval_summary &lt;- function(data, var) {\n  var_enquo &lt;- rlang::enquo(var)\n\n  summarized &lt;- data |&gt;\n    dplyr::group_by(!!var_enquo) |&gt;\n    dplyr::summarize(\n      n = dplyr::n(),\n      approval_rate = mean(approved, na.rm = TRUE),\n      .groups = \"drop\"\n    ) |&gt;\n    dplyr::mutate(approval_rate = round(approval_rate * 100, 1))\n\n  min_rate &lt;- min(summarized$approval_rate, na.rm = TRUE)\n\n  summarized |&gt;\n    gt::gt() |&gt;\n    gt::cols_label(\n      !!var_enquo := \"Group\",\n      n = \"N\",\n      approval_rate = \"Approval Rate (%)\"\n    ) |&gt;\n    gt::fmt_number(columns = n, decimals = 0) |&gt;\n    gt::tab_options(\n      table.font.names = \"Source Sans 3\",\n      column_labels.font.weight = \"bold\",\n      column_labels.background.color = \"#ece9f9\",\n      table.border.top.width = gt::px(0),\n      table.border.bottom.width = gt::px(0),\n      heading.title.font.size = 16,\n      data_row.padding = gt::px(4),\n      table.width = gt::pct(100)\n    ) |&gt;\n    gt::tab_style(\n      style = gt::cell_text(color = \"#AF121D\", weight = \"bold\"),\n      locations = gt::cells_body(\n        columns = approval_rate,\n        rows = approval_rate == min_rate\n      )\n    ) \n}\n\n\n\nInterview Completion\n\n\nCode\nfnc_approval_summary(exercise_data, had_interview)\n\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\nFALSE\n434\n50.0\n\n\nTRUE\n595\n72.1\n\n\nNA\n1,017\n49.4\n\n\n\n\n\n\n\n\nApplicants who reported completing the interview had higher approval rates than those who did not or whose response was missing.\nThis reinforces the interview as a critical point of potential drop-off.\nMissing responses likely indicate no follow-up engagement — not necessarily ineligibility.\n\n\n\nDocument Submission Group\n\n\nCode\nfnc_approval_summary(exercise_data, doc_group)\n\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\nWith App Only\n797\n65.0\n\n\nAfter App Only\n248\n57.3\n\n\nWith + After\n213\n65.7\n\n\nNo Docs\n788\n44.2\n\n\n\n\n\n\n\n\nApproval was highest among applicants who submitted documents with their initial application.\nApplicants who submitted documents only after applying had moderately lower rates.\nThe lowest approval rate (~44%) was among those who submitted nothing online.\nSubmitting documents early is associated with better outcomes — possibly due to faster case processing or stronger signals of follow-through.\n\n\n\nHousing Stability\n\n\nCode\nfnc_approval_summary(exercise_data, stable_housing)\n\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\nFALSE\n860\n64.4\n\n\nTRUE\n1,186\n50.1\n\n\n\n\n\n\n\n\nSurprisingly, applicants reporting unstable housing had slightly higher approval rates.\nThis may reflect prioritized eligibility for those experiencing homelessness or precarious living situations.\nHousing instability may increase likelihood of approval due to expedited or simplified eligibility pathways.\n\n\n\nHousehold Size (Binned)\n\n\nCode\nfnc_approval_summary(exercise_data, household_size_bin)\n\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\n(0,1]\n1,223\n61.7\n\n\n(1,2]\n334\n52.1\n\n\n(2,3]\n227\n45.4\n\n\n(3,5]\n228\n46.1\n\n\n(5,10]\n29\n27.6\n\n\nNA\n5\n60.0\n\n\n\n\n\n\n\n\nSmaller households (1–2 people) had the highest approval rates.\nApproval declined steadily for larger households.\n\n\n\n\nZIP Code Variation\nZIP code can reflect structural factors that influence access: geography, internet connectivity, support, and even worker caseloads. While it’s not causal, it helps surface system-level variation.\n\n\nCode\n# Aggregate by ZIP (filter out sparse ZIPs)\nzip_summary &lt;- exercise_data |&gt;\n  group_by(zip) |&gt;\n  summarize(\n    n = n(),\n    approval_rate = mean(approved, na.rm = TRUE)\n  ) |&gt;\n  filter(n &gt;= 10)\n\n# Bar chart\nggplot(zip_summary, aes(x = fct_reorder(zip, approval_rate), y = approval_rate)) +\n  geom_col(fill = cfa_colors$purple) +\n  coord_flip() +\n  labs(\n    title = \"Approval Rate by ZIP Code (≥10 applications)\",\n    x = \"ZIP Code\",\n    y = \"Approval Rate\"\n  ) +\n  theme_minimal(base_family = \"sourcesans\", base_size = 14) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    axis.title = element_text(size = 13),\n    axis.text = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\nNotes:\n\nApproval rates vary from ~34% to ~69% across ZIP codes.\nThis range is large enough to suggest systematic differences, not just noise.\nHigh- and low-performing ZIPs each have reasonable sample sizes, supporting this concern.\n\n\nStatistical Test: Is ZIP Predictive of Approval?\nTo formally assess whether approval rates differ significantly by ZIP, I ran a chi-squared test:\n\n\nCode\nzip_test &lt;- exercise_data |&gt;\n  filter(!is.na(approved), !is.na(zip)) |&gt;\n  count(zip, approved) |&gt;\n  pivot_wider(names_from = approved, values_from = n, values_fill = 0) |&gt;\n  column_to_rownames(\"zip\") |&gt;\n  as.matrix() |&gt;\n  chisq.test()\n\nzip_test\n\n\n\n    Pearson's Chi-squared test\n\ndata:  as.matrix(column_to_rownames(pivot_wider(count(filter(exercise_data,     !is.na(approved), !is.na(zip)), zip, approved), names_from = approved,     values_from = n, values_fill = 0), \"zip\"))\nX-squared = 43.85, df = 27, p-value = 0.02143\n\n\nInterpretation:\n\nThe test is statistically significant at the 5% level.\nWe reject the null hypothesis: approval rates differ by ZIP in a non-random way.\nThis supports using ZIP as a signal for access disparities — even in the absence of ACS or other geospatial data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CalFresh SNAP Application Analysis",
    "section": "",
    "text": "Welcome to the CalFresh SNAP Application Analysis site, created as part of a data science take home assignment for Code for America.\nThe analysis explores factors associated with CalFresh (SNAP) application approvals in San Diego County, based on ~2,000 applications submitted via GetCalFresh.org.\nThis project aims to surface key patterns in approval outcomes and suggest potential improvements to the application process."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "CalFresh SNAP Application Analysis",
    "section": "",
    "text": "Welcome to the CalFresh SNAP Application Analysis site, created as part of a data science take home assignment for Code for America.\nThe analysis explores factors associated with CalFresh (SNAP) application approvals in San Diego County, based on ~2,000 applications submitted via GetCalFresh.org.\nThis project aims to surface key patterns in approval outcomes and suggest potential improvements to the application process."
  },
  {
    "objectID": "index.html#objectives",
    "href": "index.html#objectives",
    "title": "CalFresh SNAP Application Analysis",
    "section": "Objectives",
    "text": "Objectives\n\nIdentify which applicant characteristics are most strongly associated with approval.\nUnderstand where the process may break down (e.g., interviews, document submission).\nSuggest actionable, user-centered improvements to reduce friction in the process."
  },
  {
    "objectID": "index.html#key-questions",
    "href": "index.html#key-questions",
    "title": "CalFresh SNAP Application Analysis",
    "section": "Key Questions",
    "text": "Key Questions\n\nWhat factors are most strongly associated with CalFresh approval?\nWhere would you look next to improve the application process?"
  },
  {
    "objectID": "index.html#project-links",
    "href": "index.html#project-links",
    "title": "CalFresh SNAP Application Analysis",
    "section": "Project Links",
    "text": "Project Links\n\nGitHub Repository: Link to repo\nExercise Prompt: View exercise PDF\nData Source: Download from Google Drive"
  },
  {
    "objectID": "index.html#stakeholders",
    "href": "index.html#stakeholders",
    "title": "CalFresh SNAP Application Analysis",
    "section": "Stakeholders",
    "text": "Stakeholders\nThis analysis models the collaborative work that would involve:\n\nCode for America’s GetCalFresh team: Program designers and policy advocates.\nCounty Human Services Agencies: Decision-makers and data providers.\nApplicants: The core user base, especially those facing structural barriers to access."
  },
  {
    "objectID": "analysis.html#logistic-modeling",
    "href": "analysis.html#logistic-modeling",
    "title": "Analysis",
    "section": "Logistic Modeling",
    "text": "Logistic Modeling\nWith the variables cleaned and rescaled, I fit a logistic regression model to estimate the odds of CalFresh approval. This model includes:\n\nDemographic variables: household_size, under18_n, over_59_n\nFinancial context: income_100\nApplication behavior: docs_with_app, docs_after_app, completion_time_10\nStructural/contextual factors: stable_housing, had_interview\nGeographic variation: zip (included as a fixed effect)\n\n\n\nCode\nmodel &lt;- glm(\n  approved ~ income_100 + household_size + under18_n + over_59_n +\n    docs_with_app + docs_after_app + completion_time_10 +\n    stable_housing + had_interview + zip,\n  data = exercise_data,\n  family = binomial(link = \"logit\")\n)\n\n\nThe model uses a logistic link because the outcome — approval for CalFresh — is binary (TRUE/FALSE). This approach estimates the log odds of approval based on the applicant’s characteristics and behaviors captured in the dataset.\nNext, I’ll extract and interpret the model coefficients by converting them into odds ratios for easier interpretation."
  },
  {
    "objectID": "analysis.html#approval-rates-by-key-variables",
    "href": "analysis.html#approval-rates-by-key-variables",
    "title": "Analysis",
    "section": "Approval Rates by Key Variables",
    "text": "Approval Rates by Key Variables\nTo identify process points that may shape outcomes, I calculated approval rates across key variables.\nThis helped guide feature selection and surfaced potential intervention points early.\n\n\nCode\n# Function to summarize approval rates across any categorical variable\nfnc_approval_summary &lt;- function(data, var) {\n  var_enquo &lt;- rlang::enquo(var)\n\n  summarized &lt;- data |&gt;\n    dplyr::group_by(!!var_enquo) |&gt;\n    dplyr::summarize(\n      n = dplyr::n(),\n      approval_rate = mean(approved, na.rm = TRUE),\n      .groups = \"drop\"\n    ) |&gt;\n    dplyr::mutate(approval_rate = round(approval_rate * 100, 1))\n\n  min_rate &lt;- min(summarized$approval_rate, na.rm = TRUE)\n\n  summarized |&gt;\n    gt::gt() |&gt;\n    gt::cols_label(\n      !!var_enquo := \"Group\",\n      n = \"N\",\n      approval_rate = \"Approval Rate (%)\"\n    ) |&gt;\n    gt::fmt_number(columns = n, decimals = 0) |&gt;\n    gt::tab_options(\n      table.font.names = \"Source Sans 3\",\n      column_labels.font.weight = \"bold\",\n      column_labels.background.color = \"#ece9f9\",\n      table.border.top.width = gt::px(0),\n      table.border.bottom.width = gt::px(0),\n      heading.title.font.size = 16,\n      data_row.padding = gt::px(4),\n      table.width = gt::pct(100)\n    ) |&gt;\n    gt::tab_style(\n      style = gt::cell_text(color = \"#AF121D\", weight = \"bold\"),\n      locations = gt::cells_body(\n        columns = approval_rate,\n        rows = approval_rate == min_rate\n      )\n    ) \n}"
  },
  {
    "objectID": "analysis.html#geographic-variation-in-approval-rates",
    "href": "analysis.html#geographic-variation-in-approval-rates",
    "title": "Analysis",
    "section": "Geographic Variation in Approval Rates",
    "text": "Geographic Variation in Approval Rates\nZIP code can act as a proxy for many unmeasured factors: neighborhood conditions, access to technology, outreach efforts, or staff practices. While it’s not a causal variable, it can highlight where outcomes vary meaningfully.\n\nApproval Rates by ZIP Code\nTo reduce noise, I filtered out ZIP codes with fewer than 10 applications.\n\n\nCode\nzip_summary &lt;- exercise_data |&gt;\n  group_by(zip) |&gt;\n  summarize(\n    n = n(),\n    approval_rate = mean(approved, na.rm = TRUE)\n  ) |&gt;\n  filter(n &gt;= 10)\n\n# Bar chart of approval rate by ZIP\nggplot(zip_summary, aes(x = fct_reorder(zip, approval_rate), y = approval_rate)) +\n  geom_col(fill = cfa_colors$purple) +\n  coord_flip() +\n  labs(\n    title = \"Approval Rate by ZIP Code\",\n    x = \"ZIP Code\",\n    y = \"Approval Rate\"\n  ) +\n  theme_minimal(base_family = \"sourcesans\", base_size = 14) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", margin = margin(b = 10)),\n    axis.title = element_text(size = 13),\n    axis.text = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\nHighest Approval Rates\n\n\nCode\nzip_summary |&gt; \n  arrange(desc(approval_rate)) |&gt; \n  slice_head(n = 5)\n\n\n# A tibble: 5 × 3\n  zip       n approval_rate\n  &lt;fct&gt; &lt;int&gt;         &lt;dbl&gt;\n1 92119    29         0.690\n2 92102   123         0.667\n3 92122    24         0.667\n4 92130    20         0.65 \n5 92109    85         0.635\n\n\nLowest Approval Rates\n\n\nCode\nzip_summary |&gt; \n  arrange(approval_rate) |&gt; \n  slice_head(n = 5)\n\n\n# A tibble: 5 × 3\n  zip       n approval_rate\n  &lt;fct&gt; &lt;int&gt;         &lt;dbl&gt;\n1 92124    32         0.344\n2 92173    74         0.419\n3 92103    56         0.429\n4 92123    38         0.447\n5 92128    23         0.478\n\n\nNotes:\n\nApproval rates vary widely — from 34% in 92124 to nearly 69% in 92119.\nSome of the lowest-performing ZIPs have substantial sample sizes, suggesting meaningful geographic disparities, not just noise.\nThis may reflect:\n\nVarying access to support services (e.g., nonprofits or social workers)\nDifferences in document submission or interview follow-up\nNeighborhood-level challenges not captured in the application data\n\n\nIf time and data permit, I would:\n\nMerge in ACS data on ZIP-level poverty rate and rent burden\nUse ZIP as a random effect in a mixed-effects model to account for unobserved local variation"
  },
  {
    "objectID": "analysis.html#purpose",
    "href": "analysis.html#purpose",
    "title": "Analysis",
    "section": "Purpose",
    "text": "Purpose\nThis exploratory analysis examines factors associated with CalFresh application approval among San Diego County users of GetCalFresh.org. The goal is to:\n\nUnderstand the barriers applicants may face\nIdentify features most associated with success\nHighlight opportunities for improving user outcomes\n\nResearch Questions:\n\nWhat factors are most strongly associated with CalFresh approval?\nWhere might the process be improved to reduce unnecessary drop-off or denials?"
  },
  {
    "objectID": "analysis.html#walkthrough-of-the-application",
    "href": "analysis.html#walkthrough-of-the-application",
    "title": "Analysis",
    "section": "Walkthrough of the Application",
    "text": "Walkthrough of the Application\nBefore conducting any data analysis, I walked through the GetCalFresh.org application process myself to better understand the applicant experience. This helped clarify what each variable in the dataset represents and how users encounter them in practice.\n\n\n\nCalFresh Survey Image\n\n\n\nKey Takeaways from the Application Experience\n\nMultilingual Support is available from the start (English, Spanish, Chinese, Vietnamese), with more preferred language options at the end of the process.\nThe application is staged, moving through: household info → income → expenses → contact details → confirmation.\nApplicants receive real-time feedback on whether they may qualify, including notifications about potential expedited processing timelines.\nSubmission does not require everything at once. Document uploads and interviews can happen after submission, making these potential barriers to completion, not eligibility.\n\n\n\nFinal Survey Stages and What They Reveal\nToward the end of the process, applicants are asked to:\n\nConfirm contact information (phone, email, language preferences)\nSelect mailing address options — including a note that a mailing address is required for benefit delivery but can be substituted with PO boxes or addresses of trusted third parties\nProvide interview availability and request accommodations (e.g., interpreters, help with disabilities)\nOpt into reminders via SMS and email, which are used to prompt follow-up actions\n\nPeople can drop off at this stage — just before final submission — for reasons unrelated to eligibility, such as technical issues, unclear instructions, privacy concerns, immigration status concerns, or timing conflicts with the required interview.\n\n\nImplications for Data Analysis\nThe user experience walk through shaped my interpretation of key fields:\n\nhad_interview: Based on a follow-up text message response, not a verified system event. Missing values do not confirm no interview — just that it wasn’t captured via GetCalFresh.\ndocs_with_app vs. docs_after_app: Reflect when documentation was uploaded through the platform. Counties may have received documents by other means (mail, fax, in person).\ncompletion_time_mins: Captures elapsed time from start to finish, but may reflect interruptions or household complexity — not necessarily user effort or intent."
  },
  {
    "objectID": "analysis.html#key-takeaways-from-the-application-experience",
    "href": "analysis.html#key-takeaways-from-the-application-experience",
    "title": "Analysis",
    "section": "Key Takeaways from the Application Experience",
    "text": "Key Takeaways from the Application Experience\n\nMultilingual Support is available from the start (English, Spanish, Chinese, Vietnamese), with more preferred language options at the end of the process.\nThe application is staged, moving through: household info → income → expenses → contact details → confirmation.\nApplicants receive real-time feedback on whether they may qualify, including notifications about potential expedited processing timelines.\nSubmission does not require everything at once. Document uploads and interviews can happen after submission, making these potential barriers to completion, not eligibility."
  },
  {
    "objectID": "analysis.html#final-survey-stages-and-what-they-reveal",
    "href": "analysis.html#final-survey-stages-and-what-they-reveal",
    "title": "Analysis",
    "section": "Final Survey Stages and What They Reveal",
    "text": "Final Survey Stages and What They Reveal\nToward the end of the process, applicants are asked to:\n\nConfirm contact information (phone, email, language preferences)\nSelect mailing address options — including a note that a mailing address is required for benefit delivery but can be substituted with PO boxes or addresses of trusted third parties\nProvide interview availability and request accommodations (e.g., interpreters, help with disabilities)\nOpt into reminders via SMS and email, which are used to prompt follow-up actions\n\nPeople can drop off at this stage — just before final submission — for reasons unrelated to eligibility, such as technical issues, unclear instructions, privacy concerns, immigration status concerns, or timing conflicts with the required interview."
  },
  {
    "objectID": "analysis.html#implications-for-data-analysis",
    "href": "analysis.html#implications-for-data-analysis",
    "title": "Analysis",
    "section": "Implications for Data Analysis",
    "text": "Implications for Data Analysis\nThe user experience walk through shaped my interpretation of key fields:\n\nhad_interview: Based on a follow-up text message response, not a verified system event. Missing values do not confirm no interview — just that it wasn’t captured via GetCalFresh.\ndocs_with_app vs. docs_after_app: Reflect when documentation was uploaded through the platform. Counties may have received documents by other means (mail, fax, in person).\ncompletion_time_mins: Captures elapsed time from start to finish, but may reflect interruptions or household complexity — not necessarily user effort or intent."
  },
  {
    "objectID": "analysis.html#codebook",
    "href": "analysis.html#codebook",
    "title": "Analysis",
    "section": "Codebook",
    "text": "Codebook\nTo ground the analysis in a shared understanding of the data, I generated a structured codebook using a custom function from my databookR package. The codebook:\n\nLists all variables in the dataset\nProvides plain-language descriptions for each field\nSummarizes data type, missingness, and key statistics\n\n\n\nCode\n# Add descriptions to variables\nvar_desc &lt;- list(\n  app_id               = \"Unique identifier for each application\",\n  completion_time_mins = \"Time taken to complete the application, in minutes\",\n  household_size       = \"Number of people applying for CalFresh in the household\",\n  income               = \"Total household income in the last 30 days (randomized slightly for privacy)\",\n  docs_with_app        = \"Count of verification documents uploaded with the initial application\",\n  docs_after_app       = \"Count of verification documents uploaded after application (via Later Docs)\",\n  under18_n            = \"Number of children age 17 or younger included in the application\",\n  over_59_n            = \"Number of adults age 60 or older included in the application\",\n  stable_housing       = \"TRUE if applicant rents or owns the place they sleep; FALSE otherwise\",\n  had_interview        = \"TRUE if applicant reported completing the required interview; may be missing\",\n  zip                  = \"ZIP code where the applicant lives or stays\",\n  approved             = \"TRUE if the application was approved for CalFresh by the county\"\n)\n\n# Generate codebook\ndatabookR::databook(exercise_data, var_descriptions = var_desc)\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Name\nVariable Description\nVariable Type\nNumber of Unique Values\nPercentage Missing\nStatistics\n\n\n\n\napp_id\nUnique identifier for each application\nnumeric\n2046\n0.0%\nMin: 1.0\nAvg: 38866.9\nMedian: 38066.5\nMax: 110550.0\nSD: 25305.4\n\n\ncompletion_time_mins\nTime taken to complete the application, in minutes\nnumeric\n2046\n0.0%\nMin: 2.3\nAvg: 21.4\nMedian: 10.4\nMax: 8551.8\nSD: 195.7\n\n\nhousehold_size\nNumber of people applying for CalFresh in the household\nnumeric\n10\n0.2%\nMin: 1.0\nAvg: 1.8\nMedian: 1.0\nMax: 12.0\nSD: 1.3\n\n\nincome\nTotal household income in the last 30 days (randomized slightly for privacy)\nnumeric\n888\n0.0%\nMin: 0.0\nAvg: 936.0\nMedian: 270.0\nMax: 9779.0\nSD: 1228.9\n\n\ndocs_with_app\nCount of verification documents uploaded with the initial application\nnumeric\n19\n0.0%\nMin: 0.0\nAvg: 1.3\nMedian: 0.0\nMax: 25.0\nSD: 2.2\n\n\ndocs_after_app\nCount of verification documents uploaded after application (via Later Docs)\nnumeric\n20\n0.0%\nMin: 0.0\nAvg: 0.8\nMedian: 0.0\nMax: 29.0\nSD: 2.1\n\n\nunder18_n\nNumber of children age 17 or younger included in the application\nnumeric\n7\n0.2%\nMin: 0.0\nAvg: 0.5\nMedian: 0.0\nMax: 6.0\nSD: 1.0\n\n\nover_59_n\nNumber of adults age 60 or older included in the application\nnumeric\n3\n0.2%\nMin: 0.0\nAvg: 0.1\nMedian: 0.0\nMax: 2.0\nSD: 0.3\n\n\nstable_housing\nTRUE if applicant rents or owns the place they sleep; FALSE otherwise\nlogical\n2\n0.0%\nTRUE: 1186 (58.0%)\nFALSE: 860 (42.0%)\n\n\nhad_interview\nTRUE if applicant reported completing the required interview; may be missing\nlogical\n2\n49.7%\nTRUE: 595 (57.8%)\nFALSE: 434 (42.2%)\n\n\nzip\nZIP code where the applicant lives or stays\nfactor\n28\n0.0%\nTop 5 Categories:\n92105 = 162 (7.9%)\n92114 = 157 (7.7%)\n92113 = 155 (7.6%)\n92115 = 133 (6.5%)\n92154 = 128 (6.3%)\n\n\napproved\nTRUE if the application was approved for CalFresh by the county\nlogical\n2\n0.0%\nTRUE: 1148 (56.1%)\nFALSE: 898 (43.9%)\n\n\nhousehold_size_bin\nDescription needed.\nfactor\n5\n0.2%\nAll Categories:\n(0,1] = 1223 (59.9%)\n(1,2] = 334 (16.4%)\n(3,5] = 228 (11.2%)\n(2,3] = 227 (11.1%)\n(5,10] = 29 (1.4%)\n\n\ndoc_group\nDescription needed.\nfactor\n4\n0.0%\nAll Categories:\nWith App Only = 797 (39.0%)\nNo Docs = 788 (38.5%)\nAfter App Only = 248 (12.1%)\nWith + After = 213 (10.4%)\n\n\n\n\n\n\n\nNotes:\n\nhad_interview has ~50% missingness, consistent with its self-reported source\nDocument counts (docs_with_app, docs_after_app) are zero-inflated and right-skewed\nOnly 4 missing values in demographic fields like household_size, under18_n, and over_59_n."
  },
  {
    "objectID": "analysis.html#missingness",
    "href": "analysis.html#missingness",
    "title": "Analysis",
    "section": "Missingness",
    "text": "Missingness\n\n\nCode\nvis_miss(exercise_data)\n\n\n\n\n\n\n\n\n\nOnly had_interview contains meaningful missingness. All other fields are effectively complete."
  },
  {
    "objectID": "analysis.html#distribution-of-key-variables",
    "href": "analysis.html#distribution-of-key-variables",
    "title": "Analysis",
    "section": "Distribution of Key Variables",
    "text": "Distribution of Key Variables\nI reviewed numeric variables to assess skew, outliers, and plausible ranges.\n\n\nCode\n# Custom binwidths for clarity\nbinwidths &lt;- list(\n  income = 250,\n  completion_time_mins = 40,\n  docs_with_app = 1,\n  docs_after_app = 1,\n  household_size = 1,\n  under18_n = 1,\n  over_59_n = 1\n)\n\n# Plotting function\n# Updated plot_var with optional filter for extreme values\nplot_var &lt;- function(var, title = NULL, max_x = NULL) {\n  data &lt;- exercise_data\n  if (!is.null(max_x)) {\n    data &lt;- data |&gt; filter(.data[[var]] &lt;= max_x)\n  }\n\n  ggplot(data, aes(.data[[var]])) +\n    geom_histogram(\n      binwidth = binwidths[[var]],\n      fill = cfa_colors$blue,\n      color = \"white\",\n      na.rm = TRUE\n    ) +\n    labs(\n      title = title %||% var,\n      x = var,\n      y = \"Count\"\n    ) +\n    theme_minimal(base_family = \"sourcesans\", base_size = 14) +\n    theme(\n      plot.title = element_text(size = 16, face = \"bold\", margin = margin(b = 10)),\n      axis.title = element_text(size = 13),\n      axis.text = element_text(size = 12)\n    )\n}\n\n\n# Generate all plots\nwrap_plots(\n  plot_var(\"income\", \"Monthly Income\"),\n  plot_var(\"completion_time_mins\", \"App Completion Time (Minutes)\", max_x = 120),\n  plot_var(\"docs_with_app\", \"Docs Uploaded With App\"),\n  plot_var(\"docs_after_app\", \"Docs Uploaded After App\"),\n  plot_var(\"household_size\", \"Household Size\"),\n  plot_var(\"under18_n\", \"Children in Household\"),\n  plot_var(\"over_59_n\", \"Older Adults in Household\"),\n  ncol = 2\n)\n\n\n\n\n\n\n\n\n\nNotes:\n\nIncome is right-skewed. Most applicants report monthly income between $0–$500, consistent with SNAP targeting.\nCompletion time clusters under 20 minutes. Outliers over 2 hours likely reflect interruptions.\nDocument fields show many zeros — many applicants do not submit documents online.\nHousehold size is small. Median = 1. Most applicants live alone or with one dependent.\nChild and older adult counts are near-zero for most, but tails exist."
  },
  {
    "objectID": "analysis.html#correlation-and-redundancy-check",
    "href": "analysis.html#correlation-and-redundancy-check",
    "title": "Analysis",
    "section": "Correlation and Redundancy Check",
    "text": "Correlation and Redundancy Check\nBefore building a model, I assessed relationships between predictors to check for multicollinearity.\nMulticollinearity can:\n\nInflate coefficient variance\nObscure which features are truly associated with approval\nUndermine interpretability — which is a important in this context\n\nI used two methods:\n\nPairwise correlations for numeric variables\nVariance Inflation Factor (VIF) in a preliminary logistic regression\n\n\n\nCode\n# Subset numeric predictors\nnum_vars &lt;- exercise_data |&gt;\n  select(income, household_size, under18_n, over_59_n, \n         docs_with_app, docs_after_app, completion_time_mins)\n\n# Correlation matrix\ncor_matrix &lt;- cor(num_vars, use = \"complete.obs\")\n\n# Visualize correlation matrix\ncorrplot(cor_matrix, method = \"circle\", type = \"upper\", \n         tl.cex = 0.8, tl.col = \"black\")\n\n\n\n\n\n\n\n\n\nNotes:\n\nunder18_n and household_size are moderately correlated, which is expected.\nOther variable pairs show low correlation, suggesting minimal redundancy.\n\n\n\nCode\n# Quick VIF check with basic logistic model\nvif_model &lt;- glm(\n  approved ~ income + household_size + under18_n + over_59_n +\n    docs_with_app + docs_after_app + completion_time_mins + \n    stable_housing + had_interview,\n  data = exercise_data,\n  family = binomial()\n)\n\ncar::vif(vif_model)\n\n\n              income       household_size            under18_n \n            1.570242             4.949500             4.810768 \n           over_59_n        docs_with_app       docs_after_app \n            1.082801             1.071075             1.094315 \ncompletion_time_mins       stable_housing        had_interview \n            1.012481             1.241863             1.105751 \n\n\n\nhousehold_size (4.95) and under18_n (4.81) show moderate multicollinearity — expected due to their conceptual overlap.\nAll other variables have VIFs below 2.\n\nBoth variables will likely be retained. While correlated, they reflect different eligibility factors: household size affects income limits, while the presence of children may affect processing or priority."
  },
  {
    "objectID": "analysis.html#interview-completion",
    "href": "analysis.html#interview-completion",
    "title": "Analysis",
    "section": "Interview Completion",
    "text": "Interview Completion\n\n\nCode\nfnc_approval_summary(exercise_data, had_interview)\n\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\nFALSE\n434\n50.0\n\n\nTRUE\n595\n72.1\n\n\nNA\n1,017\n49.4\n\n\n\n\n\n\n\n\nApplicants who reported completing the interview had higher approval rates than those who did not or whose response was missing.\nThis reinforces the interview as a critical point of potential drop-off.\nMissing responses likely indicate no follow-up engagement — not necessarily ineligibility."
  },
  {
    "objectID": "analysis.html#document-submission-group",
    "href": "analysis.html#document-submission-group",
    "title": "Analysis",
    "section": "Document Submission Group",
    "text": "Document Submission Group\n\n\nCode\nfnc_approval_summary(exercise_data, doc_group)\n\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\nWith App Only\n797\n65.0\n\n\nAfter App Only\n248\n57.3\n\n\nWith + After\n213\n65.7\n\n\nNo Docs\n788\n44.2\n\n\n\n\n\n\n\n\nApproval was highest among applicants who submitted documents with their initial application.\nApplicants who submitted documents only after applying had moderately lower rates.\nThe lowest approval rate (~44%) was among those who submitted nothing online.\nSubmitting documents early is associated with better outcomes — possibly due to faster case processing or stronger signals of follow-through."
  },
  {
    "objectID": "analysis.html#housing-stability",
    "href": "analysis.html#housing-stability",
    "title": "Analysis",
    "section": "Housing Stability",
    "text": "Housing Stability\n\n\nCode\nfnc_approval_summary(exercise_data, stable_housing)\n\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\nFALSE\n860\n64.4\n\n\nTRUE\n1,186\n50.1\n\n\n\n\n\n\n\n\nSurprisingly, applicants reporting unstable housing had slightly higher approval rates.\nThis may reflect prioritized eligibility for those experiencing homelessness or precarious living situations.\nHousing instability may increase likelihood of approval due to expedited or simplified eligibility pathways."
  },
  {
    "objectID": "analysis.html#household-size-binned",
    "href": "analysis.html#household-size-binned",
    "title": "Analysis",
    "section": "Household Size (Binned)",
    "text": "Household Size (Binned)\n\n\nCode\nfnc_approval_summary(exercise_data, household_size_bin)\n\n\n\n\n\n\n\n\nGroup\nN\nApproval Rate (%)\n\n\n\n\n(0,1]\n1,223\n61.7\n\n\n(1,2]\n334\n52.1\n\n\n(2,3]\n227\n45.4\n\n\n(3,5]\n228\n46.1\n\n\n(5,10]\n29\n27.6\n\n\nNA\n5\n60.0\n\n\n\n\n\n\n\n\nSmaller households (1–2 people) had the highest approval rates.\nApproval declined steadily for larger households."
  },
  {
    "objectID": "analysis.html#statistical-test-is-zip-predictive-of-approval",
    "href": "analysis.html#statistical-test-is-zip-predictive-of-approval",
    "title": "Analysis",
    "section": "Statistical Test: Is ZIP Predictive of Approval?",
    "text": "Statistical Test: Is ZIP Predictive of Approval?\nTo formally assess whether approval rates differ significantly by ZIP, I ran a chi-squared test:\n\n\nCode\nzip_test &lt;- exercise_data |&gt;\n  filter(!is.na(approved), !is.na(zip)) |&gt;\n  count(zip, approved) |&gt;\n  pivot_wider(names_from = approved, values_from = n, values_fill = 0) |&gt;\n  column_to_rownames(\"zip\") |&gt;\n  as.matrix() |&gt;\n  chisq.test()\n\nzip_test\n\n\n\n    Pearson's Chi-squared test\n\ndata:  as.matrix(column_to_rownames(pivot_wider(count(filter(exercise_data,     !is.na(approved), !is.na(zip)), zip, approved), names_from = approved,     values_from = n, values_fill = 0), \"zip\"))\nX-squared = 43.85, df = 27, p-value = 0.02143\n\n\nInterpretation:\n\nThe test is statistically significant at the 5% level.\nWe reject the null hypothesis: approval rates differ by ZIP in a non-random way.\nThis supports using ZIP as a signal for access disparities — even in the absence of ACS or other geospatial data."
  },
  {
    "objectID": "analysis.html#income",
    "href": "analysis.html#income",
    "title": "Analysis",
    "section": "Income",
    "text": "Income\n\nCreated a new variable `income_500, which scales income in units of $500 for more interpretable model coefficients.\nExample: A coefficient of –0.3 now means a 1-point drop in approval odds per $500 increase in monthly income.\n\n\n\nCode\nexercise_data &lt;- exercise_data |&gt;\n  mutate(income_500 = income / 500)\n\n\nApplication Completion Time\n\nCapped extreme values above 180 minutes to reduce the influence of long-tail outliers.\nCreated a binary flag long_app for applications that took over one hour, which may indicate interruptions or complexity.\n\n\n\nCode\nexercise_data &lt;- exercise_data |&gt;\n  mutate(\n    completion_time_capped = if_else(completion_time_mins &gt; 180, 180, completion_time_mins),\n    long_app = completion_time_mins &gt; 60\n  )\n\n\nDocument Uploads\n\nCreated total_docs to capture total documentation effort across both stages (with and after application).\nAdded a binned version total_docs_bin to explore non-linear patterns in document count and approval.\n\n\n\nCode\nexercise_data &lt;- exercise_data |&gt;\n  mutate(\n    total_docs = docs_with_app + docs_after_app,\n    total_docs_bin = case_when(\n      total_docs == 0 ~ \"0\",\n      total_docs &lt;= 2 ~ \"1–2\",\n      total_docs &lt;= 5 ~ \"3–5\",\n      TRUE ~ \"6+\"\n    ) |&gt; factor(levels = c(\"0\", \"1–2\", \"3–5\", \"6+\"))\n  )\n\n\nInterview Completion (Self-Reported)\n\nRe-coded had_interview into a two-level categorical variable, interview_completed:\n“Completed” if applicant responded “yes” via SMS\n“Not confirmed” for both “no” and missing, since missing likely means no engagement\n\n\n\nCode\nexercise_data &lt;- exercise_data |&gt;\n  mutate(interview_completed = case_when(\n    had_interview == TRUE ~ \"Completed\",\n    TRUE ~ \"Not confirmed\"\n  ) |&gt; factor(levels = c(\"Not confirmed\", \"Completed\")))\n\n\nThese transformations prepare the dataset for modeling while maintaining interpretability for stakeholders."
  },
  {
    "objectID": "analysis.html#model-specification",
    "href": "analysis.html#model-specification",
    "title": "Analysis",
    "section": "Model Specification",
    "text": "Model Specification\n\n\nCode\napproval_model &lt;- glm(\n  approved ~ income_500 + household_size + under18_n + over_59_n +\n    docs_with_app + docs_after_app + completion_time_capped +\n    stable_housing + interview_completed,\n  data = exercise_data,\n  family = binomial()\n)\n\nsummary(approval_model)\n\n\n\nCall:\nglm(formula = approved ~ income_500 + household_size + under18_n + \n    over_59_n + docs_with_app + docs_after_app + completion_time_capped + \n    stable_housing + interview_completed, family = binomial(), \n    data = exercise_data)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                   0.628432   0.131272   4.787 1.69e-06 ***\nincome_500                   -0.412618   0.029816 -13.839  &lt; 2e-16 ***\nhousehold_size               -0.125768   0.088893  -1.415  0.15712    \nunder18_n                     0.300545   0.117048   2.568  0.01024 *  \nover_59_n                     0.121020   0.155961   0.776  0.43777    \ndocs_with_app                 0.116576   0.025326   4.603 4.16e-06 ***\ndocs_after_app                0.075872   0.027076   2.802  0.00507 ** \ncompletion_time_capped       -0.001958   0.002632  -0.744  0.45674    \nstable_housingTRUE           -0.086942   0.112313  -0.774  0.43887    \ninterview_completedCompleted  1.098309   0.118276   9.286  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2800.1  on 2041  degrees of freedom\nResidual deviance: 2373.5  on 2032  degrees of freedom\n  (4 observations deleted due to missingness)\nAIC: 2393.5\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nCoefficient Interpretation\nThis logistic regression estimates the change in log-odds of approval for each predictor, holding other variables constant.\nKey observations:\n\nincome_500: Strong and statistically significant. A $500 increase in income is associated with a 0.41 decrease in the log-odds of approval (p &lt; 0.001).\ninterview_completedCompleted: The largest effect. Completing the interview increases the log-odds of approval by 1.10, a strong and highly significant association (p &lt; 0.001).\ndocs_with_app and docs_after_app: Both are positive and significant. More documents are associated with higher approval odds, especially those submitted with the application.\nunder18_n: Also significant. Each additional child increases log-odds of approval by 0.30.\nhousehold_size, over_59_n, completion_time_capped, and stable_housing are not statistically significant (all p &gt; 0.05) and show small effects.\n\nThis means that once income, documentation, and interview completion are accounted for, these other variables do not explain meaningful additional variation in approval likelihood."
  },
  {
    "objectID": "analysis.html#model-coefficients-odds-ratios",
    "href": "analysis.html#model-coefficients-odds-ratios",
    "title": "Analysis",
    "section": "Model Coefficients (Odds Ratios)",
    "text": "Model Coefficients (Odds Ratios)\nTo make results more interpretable, I exponentiated the coefficients to report odds ratios — the multiplicative change in odds of approval associated with a one-unit increase in each variable."
  },
  {
    "objectID": "analysis.html#variable-selection-rationale",
    "href": "analysis.html#variable-selection-rationale",
    "title": "Analysis",
    "section": "Variable Selection Rationale",
    "text": "Variable Selection Rationale\nVariables were selected based on relevance to both CalFresh policy and user experience. The model includes:\n\nEligibility criteria: income, household size, number of children, number of older adults\nUser actions: whether documents were submitted (with or after the application), whether the interview was completed\nProcess indicators: time spent on the application, housing stability\n\nI created and tested multiple versions of several predictors (e.g., binned document counts, total documentation effort, binary flags for long application times) and retained only the most interpretable versions for the main model. These alternate variables are available for subgroup or follow-up analyses."
  },
  {
    "objectID": "analysis.html#odds-ratios-and-confidence-intervals",
    "href": "analysis.html#odds-ratios-and-confidence-intervals",
    "title": "Analysis",
    "section": "Odds Ratios and Confidence Intervals",
    "text": "Odds Ratios and Confidence Intervals\n\n\nCode\nmodel_results &lt;- broom::tidy(approval_model, exponentiate = TRUE, conf.int = TRUE)\n\nmodel_results |&gt;\n  select(term, estimate, conf.low, conf.high, p.value) |&gt;\n  mutate(across(where(is.numeric), round, 2)) |&gt;\n  gt::gt() |&gt;\n  gt::cols_label(\n    term = \"Variable\",\n    estimate = \"Odds Ratio\",\n    conf.low = \"95% CI (Low)\",\n    conf.high = \"95% CI (High)\",\n    p.value = \"P-Value\"\n  ) |&gt;\n  gt::tab_options(\n    table.font.names = \"Source Sans 3\",\n    heading.title.font.size = 16\n  )\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.numeric), round, 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n\n\n\n\n\n\nVariable\nOdds Ratio\n95% CI (Low)\n95% CI (High)\nP-Value\n\n\n\n\n(Intercept)\n1.87\n1.45\n2.43\n0.00\n\n\nincome_500\n0.66\n0.62\n0.70\n0.00\n\n\nhousehold_size\n0.88\n0.74\n1.05\n0.16\n\n\nunder18_n\n1.35\n1.07\n1.70\n0.01\n\n\nover_59_n\n1.13\n0.83\n1.53\n0.44\n\n\ndocs_with_app\n1.12\n1.07\n1.18\n0.00\n\n\ndocs_after_app\n1.08\n1.02\n1.14\n0.01\n\n\ncompletion_time_capped\n1.00\n0.99\n1.00\n0.46\n\n\nstable_housingTRUE\n0.92\n0.74\n1.14\n0.44\n\n\ninterview_completedCompleted\n3.00\n2.38\n3.79\n0.00\n\n\n\n\n\n\n\n\nOdds Ratio Interpretation\n\nInterview Completed\nApplicants who completed the interview had 3x higher odds of approval — the strongest predictor.\nIncome\nEvery $500 increase in income reduced approval odds by 34%, reflecting income-based eligibility rules.\nDocuments Submitted With Application\nEach additional document uploaded with the application increased approval odds by 12%.\nDocuments Submitted After Application\nStill helpful — associated with an 8% increase in approval odds per document.\nChildren in Household\nEach additional child increased approval odds by 35%, likely due to eligibility prioritization.\nNot Significant\nHousehold size, older adults, time to complete application, and housing status did not show meaningful associations after controlling for other factors."
  },
  {
    "objectID": "analysis.html#distribution-of-predicted-approval-probabilities",
    "href": "analysis.html#distribution-of-predicted-approval-probabilities",
    "title": "Analysis",
    "section": "Distribution of Predicted Approval Probabilities",
    "text": "Distribution of Predicted Approval Probabilities\n\n\nCode\n# ggplot(exercise_data, aes(x = predicted_prob)) +\n#   geom_histogram(fill = cfa_colors$purple, color = \"white\", bins = 30) +\n#   labs(\n#     title = \"Predicted Probability of CalFresh Approval\",\n#     x = \"Predicted Probability\",\n#     y = \"Number of Applicants\"\n#   ) +\n#   theme_minimal(base_family = \"sourcesans\", base_size = 14)\n\n\nMost applicants fall between 30% and 80% predicted approval likelihood, with some very low or very high outliers. The model spreads probabilities across a realistic range."
  },
  {
    "objectID": "analysis.html#example-effect-of-interview-completion",
    "href": "analysis.html#example-effect-of-interview-completion",
    "title": "Analysis",
    "section": "Example: Effect of Interview Completion",
    "text": "Example: Effect of Interview Completion\n\n\nCode\nmodel_data |&gt;\n  group_by(interview_completed) |&gt;\n  summarize(mean_pred_prob = round(mean(predicted_prob), 2), n = n())\n\n\n# A tibble: 2 × 3\n  interview_completed mean_pred_prob     n\n  &lt;fct&gt;                        &lt;dbl&gt; &lt;int&gt;\n1 Not confirmed                 0.5   1447\n2 Completed                     0.72   595\n\n\n\nApplicants who completed the interview had a 72% average chance of being approved.\nThose who did not complete or did not confirm the interview had just a 50% chance.\nThis 22 percentage point difference shows how critical the interview step is.\nSupporting applicants through the interview process — with reminders, assistance, or flexible scheduling — could meaningfully improve approval rates."
  },
  {
    "objectID": "analysis.html#zip-code-variation",
    "href": "analysis.html#zip-code-variation",
    "title": "Analysis",
    "section": "ZIP Code Variation",
    "text": "ZIP Code Variation\nZIP code can reflect structural factors that influence access: geography, internet connectivity, support, and even worker caseloads. While it’s not causal, it helps surface system-level variation.\n\n\nCode\n# Aggregate by ZIP (filter out sparse ZIPs)\nzip_summary &lt;- exercise_data |&gt;\n  group_by(zip) |&gt;\n  summarize(\n    n = n(),\n    approval_rate = mean(approved, na.rm = TRUE)\n  ) |&gt;\n  filter(n &gt;= 10)\n\n# Bar chart\nggplot(zip_summary, aes(x = fct_reorder(zip, approval_rate), y = approval_rate)) +\n  geom_col(fill = cfa_colors$purple) +\n  coord_flip() +\n  labs(\n    title = \"Approval Rate by ZIP Code (≥10 applications)\",\n    x = \"ZIP Code\",\n    y = \"Approval Rate\"\n  ) +\n  theme_minimal(base_family = \"sourcesans\", base_size = 14) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\"),\n    axis.title = element_text(size = 13),\n    axis.text = element_text(size = 12)\n  )\n\n\n\n\n\n\n\n\n\nNotes:\n\nApproval rates vary from ~34% to ~69% across ZIP codes.\nThis range is large enough to suggest systematic differences, not just noise.\nHigh- and low-performing ZIPs each have reasonable sample sizes, supporting this concern."
  },
  {
    "objectID": "analysis.html#variable-preparation-for-modeling",
    "href": "analysis.html#variable-preparation-for-modeling",
    "title": "Analysis",
    "section": "Variable Preparation for Modeling",
    "text": "Variable Preparation for Modeling\nBefore modeling, I transformed several variables to improve interpretability, address skew, and reflect real-world program logic. These decisions were based on exploratory analysis and domain context from CalFresh eligibility and the GetCalFresh user flow.\n\nIncome\n\nCreated a new variable `income_500, which scales income in units of $500 for more interpretable model coefficients.\nExample: A coefficient of –0.3 now means a 1-point drop in approval odds per $500 increase in monthly income.\n\n\n\nCode\nexercise_data &lt;- exercise_data |&gt;\n  mutate(income_500 = income / 500)\n\n\n\n\nApplication Completion Time\n\nCapped extreme values above 180 minutes to reduce the influence of long-tail outliers.\nCreated a binary flag long_app for applications that took over one hour, which may indicate interruptions or complexity.\n\n\n\nCode\nexercise_data &lt;- exercise_data |&gt;\n  mutate(\n    completion_time_capped = if_else(completion_time_mins &gt; 180, 180, completion_time_mins),\n    long_app = completion_time_mins &gt; 60\n  )\n\n\n\n\nDocument Uploads\n\nCreated total_docs to capture total documentation effort across both stages (with and after application).\nAdded a binned version total_docs_bin to explore non-linear patterns in document count and approval.\n\n\n\nCode\nexercise_data &lt;- exercise_data |&gt;\n  mutate(\n    total_docs = docs_with_app + docs_after_app,\n    total_docs_bin = case_when(\n      total_docs == 0 ~ \"0\",\n      total_docs &lt;= 2 ~ \"1–2\",\n      total_docs &lt;= 5 ~ \"3–5\",\n      TRUE ~ \"6+\"\n    ) |&gt; factor(levels = c(\"0\", \"1–2\", \"3–5\", \"6+\"))\n  )\n\n\n\n\nInterview Completion (Self-Reported)\n\nRe-coded had_interview into a two-level categorical variable, interview_completed:\n“Completed” if applicant responded “yes” via SMS\n“Not confirmed” for both “no” and missing, since missing likely means no engagement\n\n\n\nCode\nexercise_data &lt;- exercise_data |&gt;\n  mutate(interview_completed = case_when(\n    had_interview == TRUE ~ \"Completed\",\n    TRUE ~ \"Not confirmed\"\n  ) |&gt; factor(levels = c(\"Not confirmed\", \"Completed\")))\n\n\nThese transformations prepare the dataset for modeling while maintaining interpretability for stakeholders."
  },
  {
    "objectID": "analysis.html#diagnostics",
    "href": "analysis.html#diagnostics",
    "title": "Analysis",
    "section": "Diagnostics",
    "text": "Diagnostics\nAfter fitting the main logistic model, I checked for model fit and potential improvements:\n\n\nCode\nlibrary(pscl)\n\n\nClasses and Methods for R originally developed in the\nPolitical Science Computational Laboratory\nDepartment of Political Science\nStanford University (2002-2015),\nby and under the direction of Simon Jackman.\nhurdle and zeroinfl functions by Achim Zeileis.\n\n\nCode\n# Pseudo R-squared\npscl::pR2(approval_model)\n\n\nfitting null model for pseudo-r2\n\n\n          llh       llhNull            G2      McFadden          r2ML \n-1186.7634616 -1400.0644571   426.6019909     0.1523508     0.1885348 \n         r2CU \n    0.2526548 \n\n\nCode\n# Hosmer-Lemeshow goodness-of-fit test\nResourceSelection::hoslem.test(approval_model$y, fitted(approval_model))\n\n\n\n    Hosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  approval_model$y, fitted(approval_model)\nX-squared = 9.0452, df = 8, p-value = 0.3385\n\n\nCode\n# ROC curve and AUC\nlibrary(pROC)\n\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\n\nCode\n# Get only rows used in the model\nmodel_data &lt;- model.frame(approval_model)\n\n# Response and predicted probabilities\nactual &lt;- model_data$approved\npredicted &lt;- fitted(approval_model)\n\n# Compute ROC\nroc_obj &lt;- pROC::roc(actual, predicted)\n\n\nSetting levels: control = FALSE, case = TRUE\n\n\nSetting direction: controls &lt; cases\n\n\nCode\npROC::auc(roc_obj)\n\n\nArea under the curve: 0.7563\n\n\nCode\nplot(roc_obj, col = \"#2b1a78\", lwd = 2)\n\n\n\n\n\n\n\n\n\n\nMcFadden R² = 0.15 The model explains 15% of the variation in approval — typical for survey or behavioral data???\nHosmer-Lemeshow p = 0.34 No evidence of poor fit. The model’s predicted probabilities align well with observed outcomes.\nAUC = 0.76 (76%) The model correctly ranks an approved case higher than a denied one 76% of the time — a good result.\nOverall takeaway: The model is a strong starting point — interpretable, statistically sound, and reasonably accurate."
  }
]